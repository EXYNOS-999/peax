{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational AE (VAE)\n",
    "\n",
    "**WARNING:** This is highly experimental and hasn't really been tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Enable importing modules from the parent directory\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "assembly = 'hg19'\n",
    "window_size = 12000\n",
    "step_size = window_size / 2\n",
    "aggregation = 100\n",
    "chroms = ['chr1', 'chr22']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and normalize the data\n",
    "\n",
    "#### Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download data...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import wget\n",
    "from pathlib import Path\n",
    "\n",
    "Path('data').mkdir(parents=True, exist_ok=True) \n",
    "\n",
    "print('Download data...')\n",
    "\n",
    "# GM12878 ChIP-seq H3K27ac log10 p-val\n",
    "bw = 'data/ENCFF258KTL.bigWig'\n",
    "if not Path(bw).is_file():\n",
    "    wget.download(\n",
    "        'https://www.encodeproject.org/files/ENCFF258KTL/@@download/ENCFF258KTL.bigWig',\n",
    "        'data/ENCFF258KTL.bigWig',\n",
    "    )\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the binned genomic windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chrom: chr1 # win: 41541 Max:   168.2037875366211\n",
      "Chrom: chr22 # win: 8550 Max:   194.40118530273438\n"
     ]
    }
   ],
   "source": [
    "from ae import bigwig\n",
    "\n",
    "data_train, data_test = bigwig.chunk(\n",
    "    bw,\n",
    "    window_size,\n",
    "    step_size,\n",
    "    aggregation,\n",
    "    chroms,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Max: 35.221359405517575 Test Max:  35.953101633997726\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "cutoff = np.percentile(data_train, (0, 99.9))\n",
    "data_train_norm = np.copy(data_train)\n",
    "data_train_norm[np.where(data_train_norm < cutoff[0])] = cutoff[0]\n",
    "data_train_norm[np.where(data_train_norm > cutoff[1])] = cutoff[1]\n",
    "\n",
    "cutoff = np.percentile(data_test, (0, 99.9))\n",
    "data_test_norm = np.copy(data_test)\n",
    "data_test_norm[np.where(data_test_norm < cutoff[0])] = cutoff[0]\n",
    "data_test_norm[np.where(data_test_norm > cutoff[1])] = cutoff[1]\n",
    "\n",
    "print(\n",
    "    'Train Max: {}'.format(np.max(data_train_norm)),\n",
    "    'Test Max:  {}'.format(np.max(data_test_norm)),\n",
    ")\n",
    "\n",
    "data_train_norm = MinMaxScaler().fit_transform(data_train_norm)\n",
    "data_test_norm = MinMaxScaler().fit_transform(data_test_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the VAE models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptfind import vae\n",
    "\n",
    "num_setups = 1\n",
    "\n",
    "setups = {\n",
    "    \"intermediate_dim\": [128],\n",
    "    \"latent_dim\": [2],\n",
    "    \"use_mse\": [False],\n",
    "    \"epochs\": [150] * num_setups,\n",
    "}\n",
    "\n",
    "ens = []\n",
    "des = []\n",
    "aes = []\n",
    "\n",
    "for i in range(num_setups):\n",
    "    en, de, ae = vae.create(\n",
    "        window_size // aggregation,\n",
    "        intermediate_dim=setups['intermediate_dim'][i],\n",
    "        latent_dim=setups['latent_dim'][i],\n",
    "        use_mse=setups['use_mse'][i],\n",
    "        metrics=['accuracy'],\n",
    "        summary=True,\n",
    "        plot=True,\n",
    "    )\n",
    "    ens.append(en)\n",
    "    des.append(de)\n",
    "    aes.append(ae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 41541 samples, validate on 8550 samples\n",
      "Epoch 1/150\n",
      "41541/41541 [==============================] - 2s 50us/step - loss: 0.0698 - acc: 0.0068 - val_loss: 0.0033 - val_acc: 0.0054\n",
      "Epoch 2/150\n",
      "41541/41541 [==============================] - 1s 18us/step - loss: 0.0031 - acc: 0.0069 - val_loss: 0.0033 - val_acc: 0.0054\n",
      "Epoch 3/150\n",
      "41541/41541 [==============================] - 1s 18us/step - loss: 0.0031 - acc: 0.0069 - val_loss: 0.0033 - val_acc: 0.0055\n",
      "Epoch 4/150\n",
      "41541/41541 [==============================] - 1s 17us/step - loss: 0.0031 - acc: 0.0320 - val_loss: 0.0033 - val_acc: 0.3567\n",
      "Epoch 5/150\n",
      "41541/41541 [==============================] - 1s 17us/step - loss: 0.0031 - acc: 0.1276 - val_loss: 0.0033 - val_acc: 0.3563\n",
      "Epoch 6/150\n",
      "41541/41541 [==============================] - 1s 17us/step - loss: 0.0031 - acc: 0.1271 - val_loss: 0.0033 - val_acc: 0.3561\n",
      "Epoch 7/150\n",
      "41541/41541 [==============================] - 1s 18us/step - loss: 0.0031 - acc: 0.1041 - val_loss: 0.0033 - val_acc: 0.3563\n",
      "Epoch 8/150\n",
      "41541/41541 [==============================] - 1s 18us/step - loss: 0.0031 - acc: 0.1270 - val_loss: 0.0033 - val_acc: 0.3561\n",
      "Epoch 9/150\n",
      "41541/41541 [==============================] - 1s 18us/step - loss: 0.0031 - acc: 0.1265 - val_loss: 0.0033 - val_acc: 0.3538\n",
      "Epoch 10/150\n",
      "41541/41541 [==============================] - 1s 18us/step - loss: 0.0031 - acc: 0.1194 - val_loss: 0.0033 - val_acc: 0.3558\n",
      "Epoch 11/150\n",
      "41541/41541 [==============================] - 1s 18us/step - loss: 0.0031 - acc: 0.1257 - val_loss: 0.0033 - val_acc: 0.3556\n",
      "Epoch 12/150\n",
      "41541/41541 [==============================] - 1s 18us/step - loss: 0.0030 - acc: 0.1092 - val_loss: 0.0033 - val_acc: 0.0075\n",
      "Epoch 13/150\n",
      "41541/41541 [==============================] - 1s 18us/step - loss: 0.0030 - acc: 0.0796 - val_loss: 0.0033 - val_acc: 0.3546\n",
      "Epoch 14/150\n",
      "41541/41541 [==============================] - 1s 17us/step - loss: 0.0030 - acc: 0.1059 - val_loss: 0.0033 - val_acc: 0.3540\n",
      "Epoch 15/150\n",
      "41541/41541 [==============================] - 1s 17us/step - loss: 0.0030 - acc: 0.0775 - val_loss: 0.0032 - val_acc: 0.3542\n",
      "Epoch 16/150\n",
      "41541/41541 [==============================] - 1s 17us/step - loss: 0.0030 - acc: 0.0289 - val_loss: 0.0032 - val_acc: 0.0048\n",
      "Epoch 17/150\n",
      "41541/41541 [==============================] - 1s 17us/step - loss: 0.0027 - acc: 0.0170 - val_loss: 0.0026 - val_acc: 0.0061\n",
      "Epoch 18/150\n",
      "41541/41541 [==============================] - 1s 17us/step - loss: 0.0023 - acc: 0.0149 - val_loss: 0.0024 - val_acc: 0.0044\n",
      "Epoch 19/150\n",
      "41541/41541 [==============================] - 1s 17us/step - loss: 0.0022 - acc: 0.0081 - val_loss: 0.0023 - val_acc: 0.0049\n",
      "Epoch 20/150\n",
      "41541/41541 [==============================] - 1s 17us/step - loss: 0.0020 - acc: 0.0084 - val_loss: 0.0020 - val_acc: 0.0078\n",
      "Epoch 21/150\n",
      "41541/41541 [==============================] - 1s 17us/step - loss: 0.0018 - acc: 0.0110 - val_loss: 0.0019 - val_acc: 0.0075\n",
      "Epoch 22/150\n",
      "41541/41541 [==============================] - 1s 17us/step - loss: 0.0018 - acc: 0.0096 - val_loss: 0.0019 - val_acc: 0.0078\n",
      "Epoch 23/150\n",
      "41541/41541 [==============================] - 1s 17us/step - loss: 0.0017 - acc: 0.0154 - val_loss: 0.0018 - val_acc: 0.0090\n",
      "Epoch 24/150\n",
      "41541/41541 [==============================] - 1s 17us/step - loss: 0.0017 - acc: 0.0186 - val_loss: 0.0018 - val_acc: 0.0089\n",
      "Epoch 25/150\n",
      "41541/41541 [==============================] - 1s 18us/step - loss: 0.0016 - acc: 0.0177 - val_loss: 0.0017 - val_acc: 0.0091\n",
      "Epoch 26/150\n",
      "41541/41541 [==============================] - 1s 17us/step - loss: 0.0016 - acc: 0.0168 - val_loss: 0.0017 - val_acc: 0.0109\n",
      "Epoch 27/150\n",
      "41541/41541 [==============================] - 1s 17us/step - loss: 0.0016 - acc: 0.0131 - val_loss: 0.0016 - val_acc: 0.0084\n",
      "Epoch 28/150\n",
      "41541/41541 [==============================] - 1s 17us/step - loss: 0.0015 - acc: 0.0187 - val_loss: 0.0016 - val_acc: 0.0122\n",
      "Epoch 29/150\n",
      "41541/41541 [==============================] - 1s 17us/step - loss: 0.0015 - acc: 0.0141 - val_loss: 0.0016 - val_acc: 0.0091\n",
      "Epoch 30/150\n",
      "41541/41541 [==============================] - 1s 18us/step - loss: 0.0015 - acc: 0.0153 - val_loss: 0.0016 - val_acc: 0.0115\n",
      "Epoch 31/150\n",
      "41541/41541 [==============================] - 1s 18us/step - loss: 0.0015 - acc: 0.0143 - val_loss: 0.0015 - val_acc: 0.0119\n",
      "Epoch 32/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 0.0014 - acc: 0.0187 - val_loss: 0.0015 - val_acc: 0.0138\n",
      "Epoch 33/150\n",
      "41541/41541 [==============================] - 1s 18us/step - loss: 0.0014 - acc: 0.0199 - val_loss: 0.0015 - val_acc: 0.0130\n",
      "Epoch 34/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 0.0014 - acc: 0.0221 - val_loss: 0.0015 - val_acc: 0.0136\n",
      "Epoch 35/150\n",
      "41541/41541 [==============================] - 1s 18us/step - loss: 0.0014 - acc: 0.0299 - val_loss: 0.0015 - val_acc: 0.0103\n",
      "Epoch 36/150\n",
      "41541/41541 [==============================] - 1s 18us/step - loss: 0.0014 - acc: 0.0185 - val_loss: 0.0015 - val_acc: 0.0116\n",
      "Epoch 37/150\n",
      "41541/41541 [==============================] - 1s 18us/step - loss: 0.0014 - acc: 0.0272 - val_loss: 0.0015 - val_acc: 0.0145\n",
      "Epoch 38/150\n",
      "41541/41541 [==============================] - 1s 18us/step - loss: 0.0014 - acc: 0.0217 - val_loss: 0.0014 - val_acc: 0.0170\n",
      "Epoch 39/150\n",
      "41541/41541 [==============================] - 1s 17us/step - loss: 0.0013 - acc: 0.0239 - val_loss: 0.0014 - val_acc: 0.0174\n",
      "Epoch 40/150\n",
      "41541/41541 [==============================] - 1s 18us/step - loss: 0.0013 - acc: 0.0215 - val_loss: 0.0014 - val_acc: 0.0193\n",
      "Epoch 41/150\n",
      "41541/41541 [==============================] - 1s 18us/step - loss: 0.0013 - acc: 0.0199 - val_loss: 0.0014 - val_acc: 0.0144\n",
      "Epoch 42/150\n",
      "41541/41541 [==============================] - 1s 18us/step - loss: 0.0013 - acc: 0.0259 - val_loss: 0.0014 - val_acc: 0.0189\n",
      "Epoch 43/150\n",
      "41541/41541 [==============================] - 1s 18us/step - loss: 0.0013 - acc: 0.0228 - val_loss: 0.0014 - val_acc: 0.0198\n",
      "Epoch 44/150\n",
      "41541/41541 [==============================] - 1s 18us/step - loss: 0.0013 - acc: 0.0242 - val_loss: 0.0013 - val_acc: 0.0177\n",
      "Epoch 45/150\n",
      "41541/41541 [==============================] - 1s 18us/step - loss: 0.0013 - acc: 0.0247 - val_loss: 0.0013 - val_acc: 0.0133\n",
      "Epoch 46/150\n",
      "41541/41541 [==============================] - 1s 18us/step - loss: 0.0012 - acc: 0.0271 - val_loss: 0.0013 - val_acc: 0.0182\n",
      "Epoch 47/150\n",
      "41541/41541 [==============================] - 1s 18us/step - loss: 0.0012 - acc: 0.0248 - val_loss: 0.0013 - val_acc: 0.0153\n",
      "Epoch 48/150\n",
      "41541/41541 [==============================] - 1s 18us/step - loss: 0.0012 - acc: 0.0241 - val_loss: 0.0012 - val_acc: 0.0200\n",
      "Epoch 49/150\n",
      "41541/41541 [==============================] - 1s 18us/step - loss: 0.0011 - acc: 0.0202 - val_loss: 0.0012 - val_acc: 0.0185\n",
      "Epoch 50/150\n",
      "41541/41541 [==============================] - 1s 18us/step - loss: 0.0011 - acc: 0.0257 - val_loss: 0.0011 - val_acc: 0.0220\n",
      "Epoch 51/150\n",
      "41541/41541 [==============================] - 1s 18us/step - loss: 0.0010 - acc: 0.0377 - val_loss: 0.0011 - val_acc: 0.0199\n",
      "Epoch 52/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 0.0010 - acc: 0.0289 - val_loss: 0.0011 - val_acc: 0.0215\n",
      "Epoch 53/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 9.9141e-04 - acc: 0.0330 - val_loss: 0.0011 - val_acc: 0.0220\n",
      "Epoch 54/150\n",
      "41541/41541 [==============================] - 1s 20us/step - loss: 9.7887e-04 - acc: 0.0287 - val_loss: 0.0011 - val_acc: 0.0213\n",
      "Epoch 55/150\n",
      "41541/41541 [==============================] - 1s 17us/step - loss: 9.7041e-04 - acc: 0.0273 - val_loss: 0.0011 - val_acc: 0.0214\n",
      "Epoch 56/150\n",
      "41541/41541 [==============================] - 1s 17us/step - loss: 9.6214e-04 - acc: 0.0283 - val_loss: 0.0011 - val_acc: 0.0219\n",
      "Epoch 57/150\n",
      "41541/41541 [==============================] - 1s 17us/step - loss: 9.5000e-04 - acc: 0.0330 - val_loss: 0.0010 - val_acc: 0.0241\n",
      "Epoch 58/150\n",
      "41541/41541 [==============================] - 1s 17us/step - loss: 9.4299e-04 - acc: 0.0359 - val_loss: 0.0010 - val_acc: 0.0228\n",
      "Epoch 59/150\n",
      "41541/41541 [==============================] - 1s 17us/step - loss: 9.3663e-04 - acc: 0.0415 - val_loss: 0.0010 - val_acc: 0.0229\n",
      "Epoch 60/150\n",
      "41541/41541 [==============================] - 1s 17us/step - loss: 9.3197e-04 - acc: 0.0297 - val_loss: 0.0010 - val_acc: 0.0261\n",
      "Epoch 61/150\n",
      "41541/41541 [==============================] - 1s 17us/step - loss: 9.2497e-04 - acc: 0.0312 - val_loss: 0.0010 - val_acc: 0.0260\n",
      "Epoch 62/150\n",
      "41541/41541 [==============================] - 1s 17us/step - loss: 9.2145e-04 - acc: 0.0358 - val_loss: 0.0010 - val_acc: 0.0218\n",
      "Epoch 63/150\n",
      "41541/41541 [==============================] - 1s 17us/step - loss: 9.1845e-04 - acc: 0.0281 - val_loss: 0.0010 - val_acc: 0.0270\n",
      "Epoch 64/150\n",
      "41541/41541 [==============================] - 1s 17us/step - loss: 9.0915e-04 - acc: 0.0338 - val_loss: 0.0010 - val_acc: 0.0229\n",
      "Epoch 65/150\n",
      "41541/41541 [==============================] - 1s 17us/step - loss: 9.0218e-04 - acc: 0.0307 - val_loss: 0.0010 - val_acc: 0.0269\n",
      "Epoch 66/150\n",
      "41541/41541 [==============================] - 1s 17us/step - loss: 9.0269e-04 - acc: 0.0298 - val_loss: 0.0010 - val_acc: 0.0273\n",
      "Epoch 67/150\n",
      "41541/41541 [==============================] - 1s 18us/step - loss: 9.1184e-04 - acc: 0.0323 - val_loss: 0.0010 - val_acc: 0.0221\n",
      "Epoch 68/150\n",
      "41541/41541 [==============================] - 1s 18us/step - loss: 8.9245e-04 - acc: 0.0311 - val_loss: 0.0010 - val_acc: 0.0281\n",
      "Epoch 69/150\n",
      "41541/41541 [==============================] - 1s 17us/step - loss: 8.9291e-04 - acc: 0.0310 - val_loss: 0.0010 - val_acc: 0.0287\n",
      "Epoch 70/150\n",
      "41541/41541 [==============================] - 1s 17us/step - loss: 8.8614e-04 - acc: 0.0301 - val_loss: 0.0010 - val_acc: 0.0228\n",
      "Epoch 71/150\n",
      "41541/41541 [==============================] - 1s 17us/step - loss: 8.8287e-04 - acc: 0.0322 - val_loss: 0.0010 - val_acc: 0.0278\n",
      "Epoch 72/150\n",
      "41541/41541 [==============================] - 1s 18us/step - loss: 8.7815e-04 - acc: 0.0318 - val_loss: 0.0010 - val_acc: 0.0243\n",
      "Epoch 73/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 8.7746e-04 - acc: 0.0297 - val_loss: 0.0010 - val_acc: 0.0325\n",
      "Epoch 74/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 8.7893e-04 - acc: 0.0390 - val_loss: 0.0010 - val_acc: 0.3650\n",
      "Epoch 75/150\n",
      "41541/41541 [==============================] - 1s 18us/step - loss: 8.7643e-04 - acc: 0.0326 - val_loss: 0.0010 - val_acc: 0.0299\n",
      "Epoch 76/150\n",
      "41541/41541 [==============================] - 1s 18us/step - loss: 8.6908e-04 - acc: 0.0331 - val_loss: 0.0010 - val_acc: 0.0280\n",
      "Epoch 77/150\n",
      "41541/41541 [==============================] - 1s 18us/step - loss: 8.6642e-04 - acc: 0.0340 - val_loss: 0.0010 - val_acc: 0.0291\n",
      "Epoch 78/150\n",
      "41541/41541 [==============================] - 1s 18us/step - loss: 8.6505e-04 - acc: 0.0335 - val_loss: 0.0010 - val_acc: 0.0281\n",
      "Epoch 79/150\n",
      "41541/41541 [==============================] - 1s 18us/step - loss: 8.6350e-04 - acc: 0.0317 - val_loss: 0.0010 - val_acc: 0.0255\n",
      "Epoch 80/150\n",
      "41541/41541 [==============================] - 1s 18us/step - loss: 8.6590e-04 - acc: 0.0336 - val_loss: 0.0010 - val_acc: 0.0260\n",
      "Epoch 81/150\n",
      "41541/41541 [==============================] - 1s 18us/step - loss: 8.6315e-04 - acc: 0.0408 - val_loss: 0.0010 - val_acc: 0.0276\n",
      "Epoch 82/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 8.5995e-04 - acc: 0.0321 - val_loss: 9.9927e-04 - val_acc: 0.0284\n",
      "Epoch 83/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 8.5634e-04 - acc: 0.0337 - val_loss: 0.0010 - val_acc: 0.0268\n",
      "Epoch 84/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 8.5230e-04 - acc: 0.0376 - val_loss: 9.9932e-04 - val_acc: 0.0277\n",
      "Epoch 85/150\n",
      "41541/41541 [==============================] - 1s 20us/step - loss: 8.5392e-04 - acc: 0.0353 - val_loss: 0.0010 - val_acc: 0.0302\n",
      "Epoch 86/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 8.5426e-04 - acc: 0.0355 - val_loss: 0.0010 - val_acc: 0.0274\n",
      "Epoch 87/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 8.4907e-04 - acc: 0.0328 - val_loss: 0.0010 - val_acc: 0.0280\n",
      "Epoch 88/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 8.5004e-04 - acc: 0.0339 - val_loss: 0.0010 - val_acc: 0.0281\n",
      "Epoch 89/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 8.4524e-04 - acc: 0.0417 - val_loss: 0.0010 - val_acc: 0.0244\n",
      "Epoch 90/150\n",
      "41541/41541 [==============================] - 1s 20us/step - loss: 8.4275e-04 - acc: 0.0335 - val_loss: 9.9573e-04 - val_acc: 0.0283\n",
      "Epoch 91/150\n",
      "41541/41541 [==============================] - 1s 20us/step - loss: 8.4469e-04 - acc: 0.0341 - val_loss: 0.0010 - val_acc: 0.0301\n",
      "Epoch 92/150\n",
      "41541/41541 [==============================] - 1s 20us/step - loss: 8.3906e-04 - acc: 0.0475 - val_loss: 0.0010 - val_acc: 0.0298\n",
      "Epoch 93/150\n",
      "41541/41541 [==============================] - 1s 18us/step - loss: 8.4068e-04 - acc: 0.0338 - val_loss: 0.0010 - val_acc: 0.0303\n",
      "Epoch 94/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 8.3892e-04 - acc: 0.0335 - val_loss: 0.0010 - val_acc: 0.0291\n",
      "Epoch 95/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 8.3630e-04 - acc: 0.0335 - val_loss: 0.0010 - val_acc: 0.0320\n",
      "Epoch 96/150\n",
      "41541/41541 [==============================] - 1s 18us/step - loss: 8.3533e-04 - acc: 0.0340 - val_loss: 0.0010 - val_acc: 0.0357\n",
      "Epoch 97/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 8.3240e-04 - acc: 0.0328 - val_loss: 9.8976e-04 - val_acc: 0.0274\n",
      "Epoch 98/150\n",
      "41541/41541 [==============================] - 1s 18us/step - loss: 8.3302e-04 - acc: 0.0374 - val_loss: 0.0010 - val_acc: 0.0280\n",
      "Epoch 99/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 8.3152e-04 - acc: 0.0345 - val_loss: 0.0010 - val_acc: 0.0302\n",
      "Epoch 100/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 8.3255e-04 - acc: 0.0428 - val_loss: 0.0010 - val_acc: 0.0265\n",
      "Epoch 101/150\n",
      "41541/41541 [==============================] - 1s 20us/step - loss: 8.2565e-04 - acc: 0.0365 - val_loss: 9.9645e-04 - val_acc: 0.0316\n",
      "Epoch 102/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 8.2696e-04 - acc: 0.0355 - val_loss: 0.0010 - val_acc: 0.0312\n",
      "Epoch 103/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 8.2343e-04 - acc: 0.0365 - val_loss: 9.8972e-04 - val_acc: 0.0294\n",
      "Epoch 104/150\n",
      "41541/41541 [==============================] - 1s 20us/step - loss: 8.2130e-04 - acc: 0.0403 - val_loss: 0.0010 - val_acc: 0.0326\n",
      "Epoch 105/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 8.2031e-04 - acc: 0.0392 - val_loss: 9.9756e-04 - val_acc: 0.0342\n",
      "Epoch 106/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 8.2468e-04 - acc: 0.0325 - val_loss: 0.0010 - val_acc: 0.0296\n",
      "Epoch 107/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 8.2172e-04 - acc: 0.0352 - val_loss: 9.8789e-04 - val_acc: 0.0311\n",
      "Epoch 108/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 8.2115e-04 - acc: 0.0347 - val_loss: 9.9904e-04 - val_acc: 0.0296\n",
      "Epoch 109/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 8.1993e-04 - acc: 0.0398 - val_loss: 0.0010 - val_acc: 0.0283\n",
      "Epoch 110/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 8.1619e-04 - acc: 0.0354 - val_loss: 9.9788e-04 - val_acc: 0.0273\n",
      "Epoch 111/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 8.1503e-04 - acc: 0.0335 - val_loss: 9.9448e-04 - val_acc: 0.0316\n",
      "Epoch 112/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 8.1054e-04 - acc: 0.0354 - val_loss: 9.9024e-04 - val_acc: 0.0306\n",
      "Epoch 113/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 8.1101e-04 - acc: 0.0339 - val_loss: 9.9210e-04 - val_acc: 0.0296\n",
      "Epoch 114/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 8.1173e-04 - acc: 0.0374 - val_loss: 9.9563e-04 - val_acc: 0.0331\n",
      "Epoch 115/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 8.1140e-04 - acc: 0.0388 - val_loss: 0.0010 - val_acc: 0.0353\n",
      "Epoch 116/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 8.1026e-04 - acc: 0.0345 - val_loss: 9.8619e-04 - val_acc: 0.0326\n",
      "Epoch 117/150\n",
      "41541/41541 [==============================] - 1s 20us/step - loss: 8.0927e-04 - acc: 0.0361 - val_loss: 0.0010 - val_acc: 0.0257\n",
      "Epoch 118/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 8.1050e-04 - acc: 0.0359 - val_loss: 0.0010 - val_acc: 0.0299\n",
      "Epoch 119/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 8.0927e-04 - acc: 0.0339 - val_loss: 9.9243e-04 - val_acc: 0.0291\n",
      "Epoch 120/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 8.0427e-04 - acc: 0.0427 - val_loss: 9.8750e-04 - val_acc: 0.0305\n",
      "Epoch 121/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 8.0516e-04 - acc: 0.0452 - val_loss: 9.8943e-04 - val_acc: 0.0301\n",
      "Epoch 122/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 8.0412e-04 - acc: 0.0359 - val_loss: 0.0010 - val_acc: 0.0304\n",
      "Epoch 123/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 8.0389e-04 - acc: 0.0475 - val_loss: 9.9780e-04 - val_acc: 0.0325\n",
      "Epoch 124/150\n",
      "41541/41541 [==============================] - 1s 20us/step - loss: 8.0220e-04 - acc: 0.0356 - val_loss: 9.9555e-04 - val_acc: 0.0281\n",
      "Epoch 125/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 7.9853e-04 - acc: 0.0388 - val_loss: 9.9420e-04 - val_acc: 0.0290\n",
      "Epoch 126/150\n",
      "41541/41541 [==============================] - 1s 20us/step - loss: 8.0011e-04 - acc: 0.0333 - val_loss: 9.9059e-04 - val_acc: 0.0312\n",
      "Epoch 127/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 8.0002e-04 - acc: 0.0356 - val_loss: 9.9833e-04 - val_acc: 0.0317\n",
      "Epoch 128/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 8.0304e-04 - acc: 0.0454 - val_loss: 0.0010 - val_acc: 0.0290\n",
      "Epoch 129/150\n",
      "41541/41541 [==============================] - 1s 20us/step - loss: 7.9787e-04 - acc: 0.0462 - val_loss: 9.9179e-04 - val_acc: 0.0303\n",
      "Epoch 130/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 7.9843e-04 - acc: 0.0391 - val_loss: 9.8253e-04 - val_acc: 0.0333\n",
      "Epoch 131/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 7.9479e-04 - acc: 0.0357 - val_loss: 9.9445e-04 - val_acc: 0.0309\n",
      "Epoch 132/150\n",
      "41541/41541 [==============================] - 1s 20us/step - loss: 7.9433e-04 - acc: 0.0353 - val_loss: 9.8975e-04 - val_acc: 0.0284\n",
      "Epoch 133/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 7.9676e-04 - acc: 0.0350 - val_loss: 9.9304e-04 - val_acc: 0.0327\n",
      "Epoch 134/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 7.9383e-04 - acc: 0.0371 - val_loss: 9.9868e-04 - val_acc: 0.0306\n",
      "Epoch 135/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 7.9580e-04 - acc: 0.0362 - val_loss: 9.8834e-04 - val_acc: 0.0335\n",
      "Epoch 136/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 7.9224e-04 - acc: 0.0396 - val_loss: 9.9633e-04 - val_acc: 0.0350\n",
      "Epoch 137/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 7.9280e-04 - acc: 0.0348 - val_loss: 9.8642e-04 - val_acc: 0.0327\n",
      "Epoch 138/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 7.8829e-04 - acc: 0.0361 - val_loss: 9.9680e-04 - val_acc: 0.0313\n",
      "Epoch 139/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 7.8850e-04 - acc: 0.0354 - val_loss: 9.9014e-04 - val_acc: 0.0292\n",
      "Epoch 140/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 7.9289e-04 - acc: 0.0391 - val_loss: 9.9015e-04 - val_acc: 0.0280\n",
      "Epoch 141/150\n",
      "41541/41541 [==============================] - 1s 20us/step - loss: 7.9009e-04 - acc: 0.0370 - val_loss: 9.9901e-04 - val_acc: 0.0275\n",
      "Epoch 142/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 7.8846e-04 - acc: 0.0408 - val_loss: 9.9906e-04 - val_acc: 0.0313\n",
      "Epoch 143/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 7.8660e-04 - acc: 0.0364 - val_loss: 9.8752e-04 - val_acc: 0.0275\n",
      "Epoch 144/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 7.8664e-04 - acc: 0.0361 - val_loss: 9.8302e-04 - val_acc: 0.0338\n",
      "Epoch 145/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 7.8843e-04 - acc: 0.0392 - val_loss: 9.8989e-04 - val_acc: 0.0304\n",
      "Epoch 146/150\n",
      "41541/41541 [==============================] - 1s 20us/step - loss: 7.8490e-04 - acc: 0.0361 - val_loss: 9.9488e-04 - val_acc: 0.0324\n",
      "Epoch 147/150\n",
      "41541/41541 [==============================] - 1s 20us/step - loss: 7.8591e-04 - acc: 0.0356 - val_loss: 9.8713e-04 - val_acc: 0.0294\n",
      "Epoch 148/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 7.8478e-04 - acc: 0.0383 - val_loss: 9.9771e-04 - val_acc: 0.0326\n",
      "Epoch 149/150\n",
      "41541/41541 [==============================] - 1s 19us/step - loss: 7.8170e-04 - acc: 0.0397 - val_loss: 9.8815e-04 - val_acc: 0.0335\n",
      "Epoch 150/150\n",
      "41541/41541 [==============================] - 1s 20us/step - loss: 7.8370e-04 - acc: 0.0364 - val_loss: 0.0010 - val_acc: 0.0318\n",
      "Train on 41541 samples, validate on 8550 samples\n",
      "Epoch 1/150\n",
      "41541/41541 [==============================] - 2s 55us/step - loss: 0.0667 - acc: 0.0081 - val_loss: 0.0034 - val_acc: 0.0074\n",
      "Epoch 2/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 0.0031 - acc: 0.0087 - val_loss: 0.0034 - val_acc: 0.0074\n",
      "Epoch 3/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0031 - acc: 0.0088 - val_loss: 0.0034 - val_acc: 0.0074\n",
      "Epoch 4/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 0.0031 - acc: 0.0088 - val_loss: 0.0033 - val_acc: 0.0074\n",
      "Epoch 5/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 0.0031 - acc: 0.0088 - val_loss: 0.0033 - val_acc: 0.0074\n",
      "Epoch 6/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0031 - acc: 0.0088 - val_loss: 0.0033 - val_acc: 0.0074\n",
      "Epoch 7/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0031 - acc: 0.0088 - val_loss: 0.0033 - val_acc: 0.0074\n",
      "Epoch 8/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0031 - acc: 0.0088 - val_loss: 0.0033 - val_acc: 0.0074\n",
      "Epoch 9/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0031 - acc: 0.0088 - val_loss: 0.0033 - val_acc: 0.0074\n",
      "Epoch 10/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0031 - acc: 0.0088 - val_loss: 0.0033 - val_acc: 0.0074\n",
      "Epoch 11/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 0.0031 - acc: 0.0088 - val_loss: 0.0033 - val_acc: 0.0074\n",
      "Epoch 12/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 0.0031 - acc: 0.0088 - val_loss: 0.0033 - val_acc: 0.0074\n",
      "Epoch 13/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0031 - acc: 0.0087 - val_loss: 0.0033 - val_acc: 0.0074\n",
      "Epoch 14/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0031 - acc: 0.0249 - val_loss: 0.0033 - val_acc: 0.0078\n",
      "Epoch 15/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0030 - acc: 0.0235 - val_loss: 0.0028 - val_acc: 0.0097\n",
      "Epoch 16/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0022 - acc: 0.0212 - val_loss: 0.0023 - val_acc: 0.0049\n",
      "Epoch 17/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0021 - acc: 0.0068 - val_loss: 0.0023 - val_acc: 0.0043\n",
      "Epoch 18/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0021 - acc: 0.0074 - val_loss: 0.0023 - val_acc: 0.0057\n",
      "Epoch 19/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0021 - acc: 0.0071 - val_loss: 0.0023 - val_acc: 0.0043\n",
      "Epoch 20/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 0.0020 - acc: 0.0082 - val_loss: 0.0021 - val_acc: 0.0060\n",
      "Epoch 21/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0019 - acc: 0.0080 - val_loss: 0.0020 - val_acc: 0.0056\n",
      "Epoch 22/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0018 - acc: 0.0092 - val_loss: 0.0020 - val_acc: 0.0061\n",
      "Epoch 23/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0017 - acc: 0.0093 - val_loss: 0.0019 - val_acc: 0.0070\n",
      "Epoch 24/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0017 - acc: 0.0100 - val_loss: 0.0019 - val_acc: 0.0087\n",
      "Epoch 25/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0017 - acc: 0.0096 - val_loss: 0.0019 - val_acc: 0.0095\n",
      "Epoch 26/150\n",
      "41541/41541 [==============================] - 1s 23us/step - loss: 0.0017 - acc: 0.0106 - val_loss: 0.0018 - val_acc: 0.0089\n",
      "Epoch 27/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0017 - acc: 0.0149 - val_loss: 0.0018 - val_acc: 0.0120\n",
      "Epoch 28/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0016 - acc: 0.0108 - val_loss: 0.0018 - val_acc: 0.0124\n",
      "Epoch 29/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0016 - acc: 0.0136 - val_loss: 0.0018 - val_acc: 0.0091\n",
      "Epoch 30/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 0.0016 - acc: 0.0113 - val_loss: 0.0018 - val_acc: 0.0098\n",
      "Epoch 31/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0016 - acc: 0.0132 - val_loss: 0.0017 - val_acc: 0.0096\n",
      "Epoch 32/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0016 - acc: 0.0160 - val_loss: 0.0017 - val_acc: 0.0119\n",
      "Epoch 33/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0015 - acc: 0.0184 - val_loss: 0.0016 - val_acc: 0.0127\n",
      "Epoch 34/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0015 - acc: 0.0189 - val_loss: 0.0016 - val_acc: 0.0110\n",
      "Epoch 35/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0015 - acc: 0.0194 - val_loss: 0.0015 - val_acc: 0.0118\n",
      "Epoch 36/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0014 - acc: 0.0141 - val_loss: 0.0015 - val_acc: 0.0125\n",
      "Epoch 37/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0014 - acc: 0.0228 - val_loss: 0.0015 - val_acc: 0.0109\n",
      "Epoch 38/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0014 - acc: 0.0216 - val_loss: 0.0015 - val_acc: 0.0167\n",
      "Epoch 39/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0013 - acc: 0.0201 - val_loss: 0.0014 - val_acc: 0.0123\n",
      "Epoch 40/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0013 - acc: 0.0171 - val_loss: 0.0014 - val_acc: 0.0138\n",
      "Epoch 41/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0013 - acc: 0.0231 - val_loss: 0.0014 - val_acc: 0.0149\n",
      "Epoch 42/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 0.0013 - acc: 0.0253 - val_loss: 0.0014 - val_acc: 0.0143\n",
      "Epoch 43/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0013 - acc: 0.0217 - val_loss: 0.0014 - val_acc: 0.0189\n",
      "Epoch 44/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0013 - acc: 0.0380 - val_loss: 0.0014 - val_acc: 0.0206\n",
      "Epoch 45/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0012 - acc: 0.0251 - val_loss: 0.0014 - val_acc: 0.0142\n",
      "Epoch 46/150\n",
      "41541/41541 [==============================] - 1s 23us/step - loss: 0.0012 - acc: 0.0177 - val_loss: 0.0014 - val_acc: 0.0143\n",
      "Epoch 47/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0012 - acc: 0.0239 - val_loss: 0.0013 - val_acc: 0.0123\n",
      "Epoch 48/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0012 - acc: 0.0259 - val_loss: 0.0014 - val_acc: 0.0171\n",
      "Epoch 49/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0012 - acc: 0.0293 - val_loss: 0.0013 - val_acc: 0.0188\n",
      "Epoch 50/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0012 - acc: 0.0350 - val_loss: 0.0013 - val_acc: 0.0172\n",
      "Epoch 51/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0012 - acc: 0.0329 - val_loss: 0.0013 - val_acc: 0.0146\n",
      "Epoch 52/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0012 - acc: 0.0265 - val_loss: 0.0013 - val_acc: 0.0188\n",
      "Epoch 53/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0012 - acc: 0.0263 - val_loss: 0.0013 - val_acc: 0.0153\n",
      "Epoch 54/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0012 - acc: 0.0342 - val_loss: 0.0013 - val_acc: 0.0140\n",
      "Epoch 55/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0011 - acc: 0.0339 - val_loss: 0.0013 - val_acc: 0.3663\n",
      "Epoch 56/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0011 - acc: 0.0459 - val_loss: 0.0013 - val_acc: 0.0201\n",
      "Epoch 57/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0012 - acc: 0.0337 - val_loss: 0.0013 - val_acc: 0.0189\n",
      "Epoch 58/150\n",
      "41541/41541 [==============================] - 1s 24us/step - loss: 0.0011 - acc: 0.0310 - val_loss: 0.0012 - val_acc: 0.3682\n",
      "Epoch 59/150\n",
      "41541/41541 [==============================] - 1s 25us/step - loss: 0.0011 - acc: 0.0338 - val_loss: 0.0013 - val_acc: 0.0179\n",
      "Epoch 60/150\n",
      "41541/41541 [==============================] - 1s 23us/step - loss: 0.0011 - acc: 0.0269 - val_loss: 0.0013 - val_acc: 0.0186\n",
      "Epoch 61/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0011 - acc: 0.0224 - val_loss: 0.0013 - val_acc: 0.0220\n",
      "Epoch 62/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0011 - acc: 0.0307 - val_loss: 0.0013 - val_acc: 0.0195\n",
      "Epoch 63/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 0.0011 - acc: 0.0270 - val_loss: 0.0013 - val_acc: 0.0207\n",
      "Epoch 64/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0011 - acc: 0.0232 - val_loss: 0.0013 - val_acc: 0.0207\n",
      "Epoch 65/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0011 - acc: 0.0224 - val_loss: 0.0013 - val_acc: 0.0188\n",
      "Epoch 66/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0011 - acc: 0.0203 - val_loss: 0.0013 - val_acc: 0.0189\n",
      "Epoch 67/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0011 - acc: 0.0257 - val_loss: 0.0013 - val_acc: 0.0193\n",
      "Epoch 68/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0011 - acc: 0.0205 - val_loss: 0.0013 - val_acc: 0.0168\n",
      "Epoch 69/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0011 - acc: 0.0266 - val_loss: 0.0013 - val_acc: 0.0153\n",
      "Epoch 70/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0011 - acc: 0.0280 - val_loss: 0.0013 - val_acc: 0.0175\n",
      "Epoch 71/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0011 - acc: 0.0262 - val_loss: 0.0012 - val_acc: 0.0214\n",
      "Epoch 72/150\n",
      "41541/41541 [==============================] - 1s 23us/step - loss: 0.0011 - acc: 0.0218 - val_loss: 0.0013 - val_acc: 0.0189\n",
      "Epoch 73/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0011 - acc: 0.0221 - val_loss: 0.0012 - val_acc: 0.0181\n",
      "Epoch 74/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0011 - acc: 0.0253 - val_loss: 0.0013 - val_acc: 0.0154\n",
      "Epoch 75/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0011 - acc: 0.0229 - val_loss: 0.0012 - val_acc: 0.0216\n",
      "Epoch 76/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0010 - acc: 0.0259 - val_loss: 0.0012 - val_acc: 0.3673\n",
      "Epoch 77/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0011 - acc: 0.0290 - val_loss: 0.0012 - val_acc: 0.0209\n",
      "Epoch 78/150\n",
      "41541/41541 [==============================] - 1s 23us/step - loss: 0.0010 - acc: 0.0236 - val_loss: 0.0012 - val_acc: 0.0219\n",
      "Epoch 79/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 0.0010 - acc: 0.0244 - val_loss: 0.0012 - val_acc: 0.0205\n",
      "Epoch 80/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 0.0010 - acc: 0.0219 - val_loss: 0.0012 - val_acc: 0.0209\n",
      "Epoch 81/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0010 - acc: 0.0214 - val_loss: 0.0012 - val_acc: 0.0159\n",
      "Epoch 82/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0010 - acc: 0.0249 - val_loss: 0.0012 - val_acc: 0.0209\n",
      "Epoch 83/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0010 - acc: 0.0252 - val_loss: 0.0012 - val_acc: 0.0198\n",
      "Epoch 84/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0010 - acc: 0.0273 - val_loss: 0.0012 - val_acc: 0.0208\n",
      "Epoch 85/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0010 - acc: 0.0230 - val_loss: 0.0012 - val_acc: 0.0230\n",
      "Epoch 86/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0010 - acc: 0.0256 - val_loss: 0.0012 - val_acc: 0.0246\n",
      "Epoch 87/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0010 - acc: 0.0239 - val_loss: 0.0012 - val_acc: 0.0195\n",
      "Epoch 88/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0010 - acc: 0.0219 - val_loss: 0.0012 - val_acc: 0.0230\n",
      "Epoch 89/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0010 - acc: 0.0221 - val_loss: 0.0012 - val_acc: 0.0222\n",
      "Epoch 90/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0010 - acc: 0.0203 - val_loss: 0.0012 - val_acc: 0.0213\n",
      "Epoch 91/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0010 - acc: 0.0252 - val_loss: 0.0012 - val_acc: 0.0247\n",
      "Epoch 92/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0010 - acc: 0.0225 - val_loss: 0.0012 - val_acc: 0.0239\n",
      "Epoch 93/150\n",
      "41541/41541 [==============================] - 1s 25us/step - loss: 0.0010 - acc: 0.0290 - val_loss: 0.0012 - val_acc: 0.0219\n",
      "Epoch 94/150\n",
      "41541/41541 [==============================] - 1s 23us/step - loss: 0.0010 - acc: 0.0258 - val_loss: 0.0012 - val_acc: 0.0234\n",
      "Epoch 95/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 0.0010 - acc: 0.0268 - val_loss: 0.0012 - val_acc: 0.0157\n",
      "Epoch 96/150\n",
      "41541/41541 [==============================] - 1s 23us/step - loss: 0.0010 - acc: 0.0248 - val_loss: 0.0012 - val_acc: 0.0202\n",
      "Epoch 97/150\n",
      "41541/41541 [==============================] - 1s 23us/step - loss: 9.9787e-04 - acc: 0.0243 - val_loss: 0.0012 - val_acc: 0.3675\n",
      "Epoch 98/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 0.0010 - acc: 0.0306 - val_loss: 0.0012 - val_acc: 0.0195\n",
      "Epoch 99/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 9.9952e-04 - acc: 0.0284 - val_loss: 0.0012 - val_acc: 0.0202\n",
      "Epoch 100/150\n",
      "41541/41541 [==============================] - 1s 20us/step - loss: 9.9802e-04 - acc: 0.0268 - val_loss: 0.0012 - val_acc: 0.0177\n",
      "Epoch 101/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 9.9532e-04 - acc: 0.0237 - val_loss: 0.0012 - val_acc: 0.0192\n",
      "Epoch 102/150\n",
      "41541/41541 [==============================] - 1s 20us/step - loss: 9.9637e-04 - acc: 0.0226 - val_loss: 0.0012 - val_acc: 0.0180\n",
      "Epoch 103/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 9.9926e-04 - acc: 0.0240 - val_loss: 0.0012 - val_acc: 0.0194\n",
      "Epoch 104/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 9.9260e-04 - acc: 0.0237 - val_loss: 0.0012 - val_acc: 0.0207\n",
      "Epoch 105/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 9.9469e-04 - acc: 0.0236 - val_loss: 0.0012 - val_acc: 0.0219\n",
      "Epoch 106/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 9.9071e-04 - acc: 0.0252 - val_loss: 0.0012 - val_acc: 0.0253\n",
      "Epoch 107/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 9.8893e-04 - acc: 0.0238 - val_loss: 0.0012 - val_acc: 0.0199\n",
      "Epoch 108/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 9.8816e-04 - acc: 0.0260 - val_loss: 0.0012 - val_acc: 0.0204\n",
      "Epoch 109/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 9.9677e-04 - acc: 0.0238 - val_loss: 0.0012 - val_acc: 0.0192\n",
      "Epoch 110/150\n",
      "41541/41541 [==============================] - 1s 20us/step - loss: 9.8662e-04 - acc: 0.0297 - val_loss: 0.0012 - val_acc: 0.0218\n",
      "Epoch 111/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 9.7957e-04 - acc: 0.0298 - val_loss: 0.0012 - val_acc: 0.0258\n",
      "Epoch 112/150\n",
      "41541/41541 [==============================] - 1s 20us/step - loss: 9.7798e-04 - acc: 0.0254 - val_loss: 0.0012 - val_acc: 0.0206\n",
      "Epoch 113/150\n",
      "41541/41541 [==============================] - 1s 20us/step - loss: 9.8341e-04 - acc: 0.0332 - val_loss: 0.0012 - val_acc: 0.0219\n",
      "Epoch 114/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 9.9026e-04 - acc: 0.0238 - val_loss: 0.0012 - val_acc: 0.0201\n",
      "Epoch 115/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 9.8885e-04 - acc: 0.0243 - val_loss: 0.0012 - val_acc: 0.0220\n",
      "Epoch 116/150\n",
      "41541/41541 [==============================] - 1s 20us/step - loss: 9.6983e-04 - acc: 0.0264 - val_loss: 0.0012 - val_acc: 0.0227\n",
      "Epoch 117/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 9.7309e-04 - acc: 0.0324 - val_loss: 0.0012 - val_acc: 0.0229\n",
      "Epoch 118/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 9.7365e-04 - acc: 0.0271 - val_loss: 0.0012 - val_acc: 0.0219\n",
      "Epoch 119/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 9.7261e-04 - acc: 0.0287 - val_loss: 0.0012 - val_acc: 0.0241\n",
      "Epoch 120/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 9.7682e-04 - acc: 0.0289 - val_loss: 0.0012 - val_acc: 0.0240\n",
      "Epoch 121/150\n",
      "41541/41541 [==============================] - 1s 20us/step - loss: 9.7583e-04 - acc: 0.0248 - val_loss: 0.0012 - val_acc: 0.0267\n",
      "Epoch 122/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 9.7208e-04 - acc: 0.0267 - val_loss: 0.0012 - val_acc: 0.0215\n",
      "Epoch 123/150\n",
      "41541/41541 [==============================] - 1s 20us/step - loss: 9.7291e-04 - acc: 0.0313 - val_loss: 0.0012 - val_acc: 0.0211\n",
      "Epoch 124/150\n",
      "41541/41541 [==============================] - 1s 20us/step - loss: 9.7030e-04 - acc: 0.0273 - val_loss: 0.0012 - val_acc: 0.0226\n",
      "Epoch 125/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 9.6822e-04 - acc: 0.0314 - val_loss: 0.0012 - val_acc: 0.0250\n",
      "Epoch 126/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 9.6171e-04 - acc: 0.0274 - val_loss: 0.0012 - val_acc: 0.0225\n",
      "Epoch 127/150\n",
      "41541/41541 [==============================] - 1s 20us/step - loss: 9.6159e-04 - acc: 0.0255 - val_loss: 0.0012 - val_acc: 0.0241\n",
      "Epoch 128/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 9.7233e-04 - acc: 0.0258 - val_loss: 0.0012 - val_acc: 0.0223\n",
      "Epoch 129/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 9.6430e-04 - acc: 0.0311 - val_loss: 0.0012 - val_acc: 0.0256\n",
      "Epoch 130/150\n",
      "41541/41541 [==============================] - 1s 20us/step - loss: 9.6516e-04 - acc: 0.0275 - val_loss: 0.0012 - val_acc: 0.0199\n",
      "Epoch 131/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 9.6967e-04 - acc: 0.0291 - val_loss: 0.0012 - val_acc: 0.0202\n",
      "Epoch 132/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 9.6385e-04 - acc: 0.0281 - val_loss: 0.0012 - val_acc: 0.0230\n",
      "Epoch 133/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 9.6666e-04 - acc: 0.0270 - val_loss: 0.0012 - val_acc: 0.0228\n",
      "Epoch 134/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 9.7091e-04 - acc: 0.0286 - val_loss: 0.0012 - val_acc: 0.0229\n",
      "Epoch 135/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 9.5517e-04 - acc: 0.0315 - val_loss: 0.0012 - val_acc: 0.0216\n",
      "Epoch 136/150\n",
      "41541/41541 [==============================] - 1s 20us/step - loss: 9.5334e-04 - acc: 0.0271 - val_loss: 0.0012 - val_acc: 0.0236\n",
      "Epoch 137/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 9.5576e-04 - acc: 0.0367 - val_loss: 0.0012 - val_acc: 0.3683\n",
      "Epoch 138/150\n",
      "41541/41541 [==============================] - 1s 20us/step - loss: 9.5401e-04 - acc: 0.0335 - val_loss: 0.0012 - val_acc: 0.0226\n",
      "Epoch 139/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 9.6731e-04 - acc: 0.0300 - val_loss: 0.0011 - val_acc: 0.0187\n",
      "Epoch 140/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 9.7082e-04 - acc: 0.0268 - val_loss: 0.0012 - val_acc: 0.0189\n",
      "Epoch 141/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 9.5579e-04 - acc: 0.0279 - val_loss: 0.0012 - val_acc: 0.0241\n",
      "Epoch 142/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 9.5247e-04 - acc: 0.0315 - val_loss: 0.0012 - val_acc: 0.0211\n",
      "Epoch 143/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 9.5416e-04 - acc: 0.0336 - val_loss: 0.0012 - val_acc: 0.0189\n",
      "Epoch 144/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 9.6917e-04 - acc: 0.0252 - val_loss: 0.0012 - val_acc: 0.0216\n",
      "Epoch 145/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 9.5028e-04 - acc: 0.0289 - val_loss: 0.0012 - val_acc: 0.0240\n",
      "Epoch 146/150\n",
      "41541/41541 [==============================] - 1s 20us/step - loss: 9.4798e-04 - acc: 0.0271 - val_loss: 0.0012 - val_acc: 0.0229\n",
      "Epoch 147/150\n",
      "41541/41541 [==============================] - 1s 22us/step - loss: 9.5652e-04 - acc: 0.0284 - val_loss: 0.0012 - val_acc: 0.0198\n",
      "Epoch 148/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 9.5097e-04 - acc: 0.0273 - val_loss: 0.0011 - val_acc: 0.0239\n",
      "Epoch 149/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 9.4769e-04 - acc: 0.0306 - val_loss: 0.0012 - val_acc: 0.0227\n",
      "Epoch 150/150\n",
      "41541/41541 [==============================] - 1s 21us/step - loss: 9.4682e-04 - acc: 0.0278 - val_loss: 0.0012 - val_acc: 0.0253\n",
      "Train on 41541 samples, validate on 8550 samples\n",
      "Epoch 1/150\n",
      "41541/41541 [==============================] - 2s 60us/step - loss: 0.0432 - acc: 0.0090 - val_loss: 0.0034 - val_acc: 0.0080\n",
      "Epoch 2/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 0.0032 - acc: 0.0107 - val_loss: 0.0034 - val_acc: 0.0080\n",
      "Epoch 3/150\n",
      "41541/41541 [==============================] - 1s 25us/step - loss: 0.0032 - acc: 0.0107 - val_loss: 0.0034 - val_acc: 0.0080\n",
      "Epoch 4/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 0.0032 - acc: 0.0106 - val_loss: 0.0034 - val_acc: 0.0077\n",
      "Epoch 5/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 0.0032 - acc: 0.0105 - val_loss: 0.0034 - val_acc: 0.0077\n",
      "Epoch 6/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 0.0032 - acc: 0.0090 - val_loss: 0.0034 - val_acc: 0.0049\n",
      "Epoch 7/150\n",
      "41541/41541 [==============================] - 1s 25us/step - loss: 0.0031 - acc: 0.0071 - val_loss: 0.0033 - val_acc: 0.0051\n",
      "Epoch 8/150\n",
      "41541/41541 [==============================] - 1s 25us/step - loss: 0.0031 - acc: 0.0077 - val_loss: 0.0033 - val_acc: 0.0054\n",
      "Epoch 9/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 0.0031 - acc: 0.0068 - val_loss: 0.0033 - val_acc: 0.0053\n",
      "Epoch 10/150\n",
      "41541/41541 [==============================] - 1s 25us/step - loss: 0.0031 - acc: 0.0072 - val_loss: 0.0033 - val_acc: 0.0069\n",
      "Epoch 11/150\n",
      "41541/41541 [==============================] - 1s 25us/step - loss: 0.0031 - acc: 0.0073 - val_loss: 0.0033 - val_acc: 0.0071\n",
      "Epoch 12/150\n",
      "41541/41541 [==============================] - 1s 25us/step - loss: 0.0031 - acc: 0.0073 - val_loss: 0.0033 - val_acc: 0.0073\n",
      "Epoch 13/150\n",
      "41541/41541 [==============================] - 1s 25us/step - loss: 0.0024 - acc: 0.0078 - val_loss: 0.0023 - val_acc: 0.0051\n",
      "Epoch 14/150\n",
      "41541/41541 [==============================] - 1s 25us/step - loss: 0.0020 - acc: 0.0080 - val_loss: 0.0021 - val_acc: 0.0075\n",
      "Epoch 15/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 0.0018 - acc: 0.0075 - val_loss: 0.0019 - val_acc: 0.0062\n",
      "Epoch 16/150\n",
      "41541/41541 [==============================] - 1s 25us/step - loss: 0.0017 - acc: 0.0095 - val_loss: 0.0019 - val_acc: 0.0078\n",
      "Epoch 17/150\n",
      "41541/41541 [==============================] - 1s 25us/step - loss: 0.0017 - acc: 0.0104 - val_loss: 0.0018 - val_acc: 0.0117\n",
      "Epoch 18/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 0.0016 - acc: 0.0117 - val_loss: 0.0016 - val_acc: 0.0115\n",
      "Epoch 19/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 0.0015 - acc: 0.0234 - val_loss: 0.0015 - val_acc: 0.0111\n",
      "Epoch 20/150\n",
      "41541/41541 [==============================] - 1s 28us/step - loss: 0.0014 - acc: 0.0182 - val_loss: 0.0014 - val_acc: 0.0151\n",
      "Epoch 21/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 0.0013 - acc: 0.0209 - val_loss: 0.0013 - val_acc: 0.0140\n",
      "Epoch 22/150\n",
      "41541/41541 [==============================] - 1s 25us/step - loss: 0.0012 - acc: 0.0313 - val_loss: 0.0012 - val_acc: 0.0158\n",
      "Epoch 23/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 0.0011 - acc: 0.0243 - val_loss: 0.0011 - val_acc: 0.0186\n",
      "Epoch 24/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 0.0011 - acc: 0.0262 - val_loss: 0.0011 - val_acc: 0.0172\n",
      "Epoch 25/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 0.0010 - acc: 0.0303 - val_loss: 0.0011 - val_acc: 0.0182\n",
      "Epoch 26/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 0.0010 - acc: 0.0202 - val_loss: 0.0011 - val_acc: 0.0174\n",
      "Epoch 27/150\n",
      "41541/41541 [==============================] - 1s 28us/step - loss: 9.8792e-04 - acc: 0.0268 - val_loss: 0.0011 - val_acc: 0.0151\n",
      "Epoch 28/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 9.7505e-04 - acc: 0.0240 - val_loss: 0.0011 - val_acc: 0.0188\n",
      "Epoch 29/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 9.6137e-04 - acc: 0.0250 - val_loss: 0.0010 - val_acc: 0.0247\n",
      "Epoch 30/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 9.4652e-04 - acc: 0.0252 - val_loss: 0.0010 - val_acc: 0.0193\n",
      "Epoch 31/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 9.4126e-04 - acc: 0.0333 - val_loss: 0.0010 - val_acc: 0.0209\n",
      "Epoch 32/150\n",
      "41541/41541 [==============================] - 1s 25us/step - loss: 9.2432e-04 - acc: 0.0261 - val_loss: 0.0010 - val_acc: 0.0199\n",
      "Epoch 33/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 9.2071e-04 - acc: 0.0339 - val_loss: 9.8973e-04 - val_acc: 0.0219\n",
      "Epoch 34/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 9.1633e-04 - acc: 0.0273 - val_loss: 9.9467e-04 - val_acc: 0.0250\n",
      "Epoch 35/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 9.0697e-04 - acc: 0.0334 - val_loss: 0.0010 - val_acc: 0.0188\n",
      "Epoch 36/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 8.9949e-04 - acc: 0.0314 - val_loss: 9.7831e-04 - val_acc: 0.0225\n",
      "Epoch 37/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 8.9570e-04 - acc: 0.0414 - val_loss: 9.7111e-04 - val_acc: 0.0228\n",
      "Epoch 38/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 8.9257e-04 - acc: 0.0319 - val_loss: 0.0010 - val_acc: 0.0206\n",
      "Epoch 39/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 8.8938e-04 - acc: 0.0289 - val_loss: 9.6720e-04 - val_acc: 0.0235\n",
      "Epoch 40/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 8.8081e-04 - acc: 0.0329 - val_loss: 0.0010 - val_acc: 0.0237\n",
      "Epoch 41/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 8.8458e-04 - acc: 0.0351 - val_loss: 9.8518e-04 - val_acc: 0.3662\n",
      "Epoch 42/150\n",
      "41541/41541 [==============================] - 1s 33us/step - loss: 8.7380e-04 - acc: 0.0381 - val_loss: 9.5526e-04 - val_acc: 0.0237\n",
      "Epoch 43/150\n",
      "41541/41541 [==============================] - 1s 31us/step - loss: 8.7379e-04 - acc: 0.0343 - val_loss: 9.4760e-04 - val_acc: 0.0255\n",
      "Epoch 44/150\n",
      "41541/41541 [==============================] - 1s 30us/step - loss: 8.5885e-04 - acc: 0.0373 - val_loss: 9.4709e-04 - val_acc: 0.0264\n",
      "Epoch 45/150\n",
      "41541/41541 [==============================] - 1s 28us/step - loss: 8.6279e-04 - acc: 0.0342 - val_loss: 9.6943e-04 - val_acc: 0.0237\n",
      "Epoch 46/150\n",
      "41541/41541 [==============================] - 1s 31us/step - loss: 8.6042e-04 - acc: 0.0341 - val_loss: 9.5425e-04 - val_acc: 0.0276\n",
      "Epoch 47/150\n",
      "41541/41541 [==============================] - 1s 28us/step - loss: 8.5480e-04 - acc: 0.0326 - val_loss: 9.4781e-04 - val_acc: 0.0249\n",
      "Epoch 48/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 8.4420e-04 - acc: 0.0394 - val_loss: 9.5222e-04 - val_acc: 0.0243\n",
      "Epoch 49/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 8.5203e-04 - acc: 0.0318 - val_loss: 9.5320e-04 - val_acc: 0.0269\n",
      "Epoch 50/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 8.4292e-04 - acc: 0.0310 - val_loss: 9.4089e-04 - val_acc: 0.3724\n",
      "Epoch 51/150\n",
      "41541/41541 [==============================] - 1s 30us/step - loss: 8.4362e-04 - acc: 0.0389 - val_loss: 9.4397e-04 - val_acc: 0.0264\n",
      "Epoch 52/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 8.4371e-04 - acc: 0.0303 - val_loss: 9.6237e-04 - val_acc: 0.0281\n",
      "Epoch 53/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 8.4803e-04 - acc: 0.0308 - val_loss: 9.4251e-04 - val_acc: 0.0282\n",
      "Epoch 54/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 8.3060e-04 - acc: 0.0362 - val_loss: 9.3370e-04 - val_acc: 0.0258\n",
      "Epoch 55/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 8.2655e-04 - acc: 0.0427 - val_loss: 9.5864e-04 - val_acc: 0.0233\n",
      "Epoch 56/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 8.2289e-04 - acc: 0.0317 - val_loss: 9.3958e-04 - val_acc: 0.0267\n",
      "Epoch 57/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 8.2504e-04 - acc: 0.0332 - val_loss: 9.6427e-04 - val_acc: 0.0249\n",
      "Epoch 58/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 8.1745e-04 - acc: 0.0367 - val_loss: 9.3150e-04 - val_acc: 0.0265\n",
      "Epoch 59/150\n",
      "41541/41541 [==============================] - 1s 30us/step - loss: 8.3289e-04 - acc: 0.0350 - val_loss: 9.3177e-04 - val_acc: 0.0278\n",
      "Epoch 60/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 8.1719e-04 - acc: 0.0350 - val_loss: 9.3435e-04 - val_acc: 0.0278\n",
      "Epoch 61/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 8.1119e-04 - acc: 0.0423 - val_loss: 9.2200e-04 - val_acc: 0.0303\n",
      "Epoch 62/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 8.1349e-04 - acc: 0.0343 - val_loss: 9.3950e-04 - val_acc: 0.0267\n",
      "Epoch 63/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 8.0778e-04 - acc: 0.0368 - val_loss: 9.4692e-04 - val_acc: 0.0244\n",
      "Epoch 64/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 8.2191e-04 - acc: 0.0314 - val_loss: 9.2064e-04 - val_acc: 0.0329\n",
      "Epoch 65/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 8.0452e-04 - acc: 0.0383 - val_loss: 9.2240e-04 - val_acc: 0.0268\n",
      "Epoch 66/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 8.0517e-04 - acc: 0.0337 - val_loss: 9.3204e-04 - val_acc: 0.0287\n",
      "Epoch 67/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 7.9851e-04 - acc: 0.0370 - val_loss: 9.1996e-04 - val_acc: 0.0274\n",
      "Epoch 68/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 8.0225e-04 - acc: 0.0386 - val_loss: 9.3476e-04 - val_acc: 0.0297\n",
      "Epoch 69/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 7.9749e-04 - acc: 0.0352 - val_loss: 9.2545e-04 - val_acc: 0.0250\n",
      "Epoch 70/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 8.0901e-04 - acc: 0.0344 - val_loss: 9.3931e-04 - val_acc: 0.0310\n",
      "Epoch 71/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 8.0906e-04 - acc: 0.0370 - val_loss: 9.2739e-04 - val_acc: 0.0299\n",
      "Epoch 72/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 8.0026e-04 - acc: 0.0366 - val_loss: 9.2126e-04 - val_acc: 0.0337\n",
      "Epoch 73/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 7.8720e-04 - acc: 0.0358 - val_loss: 9.3007e-04 - val_acc: 0.0316\n",
      "Epoch 74/150\n",
      "41541/41541 [==============================] - 1s 28us/step - loss: 7.9285e-04 - acc: 0.0357 - val_loss: 9.1310e-04 - val_acc: 0.0320\n",
      "Epoch 75/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 7.8324e-04 - acc: 0.0366 - val_loss: 9.2642e-04 - val_acc: 0.0335\n",
      "Epoch 76/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 7.8432e-04 - acc: 0.0385 - val_loss: 9.2831e-04 - val_acc: 0.0313\n",
      "Epoch 77/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 7.8717e-04 - acc: 0.0346 - val_loss: 9.1054e-04 - val_acc: 0.0258\n",
      "Epoch 78/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 7.7924e-04 - acc: 0.0442 - val_loss: 9.0518e-04 - val_acc: 0.0301\n",
      "Epoch 79/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 7.7759e-04 - acc: 0.0350 - val_loss: 9.1008e-04 - val_acc: 0.0309\n",
      "Epoch 80/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 7.7833e-04 - acc: 0.0395 - val_loss: 9.1779e-04 - val_acc: 0.0306\n",
      "Epoch 81/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 7.7814e-04 - acc: 0.0368 - val_loss: 9.1162e-04 - val_acc: 0.0326\n",
      "Epoch 82/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 7.9058e-04 - acc: 0.0385 - val_loss: 9.1711e-04 - val_acc: 0.0317\n",
      "Epoch 83/150\n",
      "41541/41541 [==============================] - 1s 28us/step - loss: 7.7111e-04 - acc: 0.0375 - val_loss: 9.2019e-04 - val_acc: 0.0372\n",
      "Epoch 84/150\n",
      "41541/41541 [==============================] - 1s 28us/step - loss: 7.7155e-04 - acc: 0.0377 - val_loss: 9.5294e-04 - val_acc: 0.0315\n",
      "Epoch 85/150\n",
      "41541/41541 [==============================] - 1s 28us/step - loss: 7.7315e-04 - acc: 0.0371 - val_loss: 9.0481e-04 - val_acc: 0.0325\n",
      "Epoch 86/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 7.7088e-04 - acc: 0.0368 - val_loss: 9.1168e-04 - val_acc: 0.0360\n",
      "Epoch 87/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 7.6415e-04 - acc: 0.0371 - val_loss: 9.1484e-04 - val_acc: 0.0318\n",
      "Epoch 88/150\n",
      "41541/41541 [==============================] - 1s 28us/step - loss: 7.7410e-04 - acc: 0.0373 - val_loss: 9.1224e-04 - val_acc: 0.0311\n",
      "Epoch 89/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 7.6615e-04 - acc: 0.0395 - val_loss: 8.9957e-04 - val_acc: 0.0356\n",
      "Epoch 90/150\n",
      "41541/41541 [==============================] - 1s 29us/step - loss: 7.6328e-04 - acc: 0.0376 - val_loss: 9.2266e-04 - val_acc: 0.0304\n",
      "Epoch 91/150\n",
      "41541/41541 [==============================] - 1s 28us/step - loss: 7.6720e-04 - acc: 0.0404 - val_loss: 9.0973e-04 - val_acc: 0.0332\n",
      "Epoch 92/150\n",
      "41541/41541 [==============================] - 1s 30us/step - loss: 7.6346e-04 - acc: 0.0383 - val_loss: 9.0983e-04 - val_acc: 0.0356\n",
      "Epoch 93/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 7.6112e-04 - acc: 0.0380 - val_loss: 9.1392e-04 - val_acc: 0.0360\n",
      "Epoch 94/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 7.6068e-04 - acc: 0.0390 - val_loss: 9.0585e-04 - val_acc: 0.0320\n",
      "Epoch 95/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 7.6730e-04 - acc: 0.0367 - val_loss: 9.1447e-04 - val_acc: 0.0313\n",
      "Epoch 96/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 7.6279e-04 - acc: 0.0431 - val_loss: 9.1328e-04 - val_acc: 0.0333\n",
      "Epoch 97/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 7.5682e-04 - acc: 0.0379 - val_loss: 8.9942e-04 - val_acc: 0.0354\n",
      "Epoch 98/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 7.5722e-04 - acc: 0.0389 - val_loss: 9.1817e-04 - val_acc: 0.0335\n",
      "Epoch 99/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 7.5267e-04 - acc: 0.0396 - val_loss: 9.0635e-04 - val_acc: 0.0322\n",
      "Epoch 100/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 7.5696e-04 - acc: 0.0405 - val_loss: 9.0843e-04 - val_acc: 0.0320\n",
      "Epoch 101/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 7.5160e-04 - acc: 0.0403 - val_loss: 9.0706e-04 - val_acc: 0.0305\n",
      "Epoch 102/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 7.4996e-04 - acc: 0.0395 - val_loss: 9.0530e-04 - val_acc: 0.0347\n",
      "Epoch 103/150\n",
      "41541/41541 [==============================] - 1s 28us/step - loss: 7.4895e-04 - acc: 0.0416 - val_loss: 9.0717e-04 - val_acc: 0.0366\n",
      "Epoch 104/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 7.4906e-04 - acc: 0.0385 - val_loss: 9.0295e-04 - val_acc: 0.0342\n",
      "Epoch 105/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 7.5125e-04 - acc: 0.0387 - val_loss: 9.1289e-04 - val_acc: 0.0350\n",
      "Epoch 106/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 7.5084e-04 - acc: 0.0397 - val_loss: 9.0548e-04 - val_acc: 0.0318\n",
      "Epoch 107/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 7.4570e-04 - acc: 0.0420 - val_loss: 9.0963e-04 - val_acc: 0.0381\n",
      "Epoch 108/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 7.5376e-04 - acc: 0.0388 - val_loss: 9.1497e-04 - val_acc: 0.0360\n",
      "Epoch 109/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 7.4879e-04 - acc: 0.0409 - val_loss: 9.0248e-04 - val_acc: 0.0343\n",
      "Epoch 110/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 7.4360e-04 - acc: 0.0399 - val_loss: 9.0409e-04 - val_acc: 0.0360\n",
      "Epoch 111/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 7.4965e-04 - acc: 0.0400 - val_loss: 9.0711e-04 - val_acc: 0.0359\n",
      "Epoch 112/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 7.4214e-04 - acc: 0.0411 - val_loss: 9.0119e-04 - val_acc: 0.0323\n",
      "Epoch 113/150\n",
      "41541/41541 [==============================] - 1s 28us/step - loss: 7.3807e-04 - acc: 0.0417 - val_loss: 9.0297e-04 - val_acc: 0.0350\n",
      "Epoch 114/150\n",
      "41541/41541 [==============================] - 1s 25us/step - loss: 7.3901e-04 - acc: 0.0415 - val_loss: 8.9873e-04 - val_acc: 0.0364\n",
      "Epoch 115/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 7.3733e-04 - acc: 0.0421 - val_loss: 9.0867e-04 - val_acc: 0.0354\n",
      "Epoch 116/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 7.3482e-04 - acc: 0.0409 - val_loss: 9.0031e-04 - val_acc: 0.0364\n",
      "Epoch 117/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 7.4257e-04 - acc: 0.0401 - val_loss: 9.0691e-04 - val_acc: 0.0356\n",
      "Epoch 118/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 7.4998e-04 - acc: 0.0407 - val_loss: 9.0269e-04 - val_acc: 0.0352\n",
      "Epoch 119/150\n",
      "41541/41541 [==============================] - 1s 28us/step - loss: 7.3464e-04 - acc: 0.0423 - val_loss: 8.9352e-04 - val_acc: 0.0374\n",
      "Epoch 120/150\n",
      "41541/41541 [==============================] - 1s 28us/step - loss: 7.3843e-04 - acc: 0.0413 - val_loss: 8.9397e-04 - val_acc: 0.0366\n",
      "Epoch 121/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 7.2985e-04 - acc: 0.0407 - val_loss: 9.0109e-04 - val_acc: 0.0370\n",
      "Epoch 122/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 7.3602e-04 - acc: 0.0430 - val_loss: 8.9520e-04 - val_acc: 0.0351\n",
      "Epoch 123/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 7.4742e-04 - acc: 0.0406 - val_loss: 9.1023e-04 - val_acc: 0.0361\n",
      "Epoch 124/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 7.3509e-04 - acc: 0.0418 - val_loss: 9.0764e-04 - val_acc: 0.0381\n",
      "Epoch 125/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 7.3389e-04 - acc: 0.0427 - val_loss: 8.9424e-04 - val_acc: 0.0375\n",
      "Epoch 126/150\n",
      "41541/41541 [==============================] - 1s 28us/step - loss: 7.2857e-04 - acc: 0.0421 - val_loss: 8.9833e-04 - val_acc: 0.0399\n",
      "Epoch 127/150\n",
      "41541/41541 [==============================] - 1s 28us/step - loss: 7.2727e-04 - acc: 0.0415 - val_loss: 8.9939e-04 - val_acc: 0.0377\n",
      "Epoch 128/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 7.2770e-04 - acc: 0.0428 - val_loss: 9.1639e-04 - val_acc: 0.0360\n",
      "Epoch 129/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 7.2902e-04 - acc: 0.0433 - val_loss: 8.9738e-04 - val_acc: 0.0375\n",
      "Epoch 130/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 7.2365e-04 - acc: 0.0434 - val_loss: 9.0871e-04 - val_acc: 0.0367\n",
      "Epoch 131/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 7.3253e-04 - acc: 0.0429 - val_loss: 8.9765e-04 - val_acc: 0.0406\n",
      "Epoch 132/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 7.2922e-04 - acc: 0.0403 - val_loss: 8.9427e-04 - val_acc: 0.0357\n",
      "Epoch 133/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 7.2687e-04 - acc: 0.0417 - val_loss: 8.9917e-04 - val_acc: 0.0375\n",
      "Epoch 134/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 7.2935e-04 - acc: 0.0421 - val_loss: 9.1028e-04 - val_acc: 0.0358\n",
      "Epoch 135/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 7.2275e-04 - acc: 0.0441 - val_loss: 9.0277e-04 - val_acc: 0.0388\n",
      "Epoch 136/150\n",
      "41541/41541 [==============================] - 1s 30us/step - loss: 7.3088e-04 - acc: 0.0420 - val_loss: 9.1010e-04 - val_acc: 0.0354\n",
      "Epoch 137/150\n",
      "41541/41541 [==============================] - 1s 28us/step - loss: 7.2581e-04 - acc: 0.0430 - val_loss: 8.9519e-04 - val_acc: 0.0349\n",
      "Epoch 138/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 7.2128e-04 - acc: 0.0428 - val_loss: 8.9850e-04 - val_acc: 0.0367\n",
      "Epoch 139/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 7.2055e-04 - acc: 0.0411 - val_loss: 8.9503e-04 - val_acc: 0.0407\n",
      "Epoch 140/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 7.2424e-04 - acc: 0.0424 - val_loss: 8.9152e-04 - val_acc: 0.0389\n",
      "Epoch 141/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 7.3001e-04 - acc: 0.0429 - val_loss: 9.1230e-04 - val_acc: 0.0338\n",
      "Epoch 142/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 7.2418e-04 - acc: 0.0419 - val_loss: 9.0713e-04 - val_acc: 0.0359\n",
      "Epoch 143/150\n",
      "41541/41541 [==============================] - 1s 28us/step - loss: 7.3146e-04 - acc: 0.0434 - val_loss: 9.3028e-04 - val_acc: 0.0339\n",
      "Epoch 144/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 7.2158e-04 - acc: 0.0416 - val_loss: 9.1416e-04 - val_acc: 0.0358\n",
      "Epoch 145/150\n",
      "41541/41541 [==============================] - 1s 28us/step - loss: 7.1921e-04 - acc: 0.0431 - val_loss: 9.0355e-04 - val_acc: 0.0357\n",
      "Epoch 146/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 7.1541e-04 - acc: 0.0436 - val_loss: 8.9555e-04 - val_acc: 0.0384\n",
      "Epoch 147/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 7.1603e-04 - acc: 0.0470 - val_loss: 9.1479e-04 - val_acc: 0.0377\n",
      "Epoch 148/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 7.1215e-04 - acc: 0.0433 - val_loss: 9.0188e-04 - val_acc: 0.0380\n",
      "Epoch 149/150\n",
      "41541/41541 [==============================] - 1s 26us/step - loss: 7.1154e-04 - acc: 0.0438 - val_loss: 9.0294e-04 - val_acc: 0.0406\n",
      "Epoch 150/150\n",
      "41541/41541 [==============================] - 1s 27us/step - loss: 7.1961e-04 - acc: 0.0424 - val_loss: 9.1577e-04 - val_acc: 0.0345\n",
      "Train on 41541 samples, validate on 8550 samples\n",
      "Epoch 1/150\n",
      "41541/41541 [==============================] - 3s 73us/step - loss: 0.0473 - acc: 0.0076 - val_loss: 0.0034 - val_acc: 0.0055\n",
      "Epoch 2/150\n",
      "41541/41541 [==============================] - 2s 36us/step - loss: 0.0032 - acc: 0.0074 - val_loss: 0.0034 - val_acc: 0.0055\n",
      "Epoch 3/150\n",
      "41541/41541 [==============================] - 2s 37us/step - loss: 0.0032 - acc: 0.0074 - val_loss: 0.0034 - val_acc: 0.0044\n",
      "Epoch 4/150\n",
      "41541/41541 [==============================] - 2s 37us/step - loss: 0.0032 - acc: 0.0069 - val_loss: 0.0034 - val_acc: 0.0055\n",
      "Epoch 5/150\n",
      "41541/41541 [==============================] - 2s 38us/step - loss: 0.0032 - acc: 0.0072 - val_loss: 0.0034 - val_acc: 0.0044\n",
      "Epoch 6/150\n",
      "41541/41541 [==============================] - 2s 37us/step - loss: 0.0032 - acc: 0.0069 - val_loss: 0.0034 - val_acc: 0.0044\n",
      "Epoch 7/150\n",
      "41541/41541 [==============================] - 2s 37us/step - loss: 0.0032 - acc: 0.0073 - val_loss: 0.0034 - val_acc: 0.0044\n",
      "Epoch 8/150\n",
      "41541/41541 [==============================] - 2s 38us/step - loss: 0.0032 - acc: 0.0066 - val_loss: 0.0034 - val_acc: 0.0044\n",
      "Epoch 9/150\n",
      "41541/41541 [==============================] - 2s 37us/step - loss: 0.0032 - acc: 0.0071 - val_loss: 0.0034 - val_acc: 0.0055\n",
      "Epoch 10/150\n",
      "41541/41541 [==============================] - 2s 37us/step - loss: 0.0032 - acc: 0.0074 - val_loss: 0.0034 - val_acc: 0.0055\n",
      "Epoch 11/150\n",
      "41541/41541 [==============================] - 2s 37us/step - loss: 0.0032 - acc: 0.0069 - val_loss: 0.0034 - val_acc: 0.0055\n",
      "Epoch 12/150\n",
      "41541/41541 [==============================] - 2s 38us/step - loss: 0.0032 - acc: 0.0070 - val_loss: 0.0034 - val_acc: 0.0044\n",
      "Epoch 13/150\n",
      "41541/41541 [==============================] - 2s 37us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0044\n",
      "Epoch 14/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0071 - val_loss: 0.0034 - val_acc: 0.0055\n",
      "Epoch 15/150\n",
      "41541/41541 [==============================] - 2s 37us/step - loss: 0.0032 - acc: 0.0072 - val_loss: 0.0034 - val_acc: 0.0055\n",
      "Epoch 16/150\n",
      "41541/41541 [==============================] - 2s 37us/step - loss: 0.0032 - acc: 0.0075 - val_loss: 0.0034 - val_acc: 0.0055\n",
      "Epoch 17/150\n",
      "41541/41541 [==============================] - 1s 36us/step - loss: 0.0032 - acc: 0.0069 - val_loss: 0.0034 - val_acc: 0.0044\n",
      "Epoch 18/150\n",
      "41541/41541 [==============================] - 2s 37us/step - loss: 0.0032 - acc: 0.0065 - val_loss: 0.0034 - val_acc: 0.0042\n",
      "Epoch 19/150\n",
      "41541/41541 [==============================] - 2s 36us/step - loss: 0.0032 - acc: 0.0069 - val_loss: 0.0034 - val_acc: 0.0042\n",
      "Epoch 20/150\n",
      "41541/41541 [==============================] - 2s 37us/step - loss: 0.0032 - acc: 0.0073 - val_loss: 0.0034 - val_acc: 0.0044\n",
      "Epoch 21/150\n",
      "41541/41541 [==============================] - 2s 37us/step - loss: 0.0032 - acc: 0.0068 - val_loss: 0.0034 - val_acc: 0.0055\n",
      "Epoch 22/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0071 - val_loss: 0.0034 - val_acc: 0.0042\n",
      "Epoch 23/150\n",
      "41541/41541 [==============================] - 2s 38us/step - loss: 0.0032 - acc: 0.0070 - val_loss: 0.0034 - val_acc: 0.0042\n",
      "Epoch 24/150\n",
      "41541/41541 [==============================] - 2s 37us/step - loss: 0.0032 - acc: 0.0070 - val_loss: 0.0034 - val_acc: 0.0042\n",
      "Epoch 25/150\n",
      "41541/41541 [==============================] - 2s 38us/step - loss: 0.0032 - acc: 0.0069 - val_loss: 0.0034 - val_acc: 0.0042\n",
      "Epoch 26/150\n",
      "41541/41541 [==============================] - 2s 37us/step - loss: 0.0032 - acc: 0.0064 - val_loss: 0.0034 - val_acc: 0.0055\n",
      "Epoch 27/150\n",
      "41541/41541 [==============================] - 2s 37us/step - loss: 0.0032 - acc: 0.0070 - val_loss: 0.0034 - val_acc: 0.0042\n",
      "Epoch 28/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0075 - val_loss: 0.0034 - val_acc: 0.0055\n",
      "Epoch 29/150\n",
      "41541/41541 [==============================] - 2s 37us/step - loss: 0.0032 - acc: 0.0070 - val_loss: 0.0034 - val_acc: 0.0044\n",
      "Epoch 30/150\n",
      "41541/41541 [==============================] - 2s 37us/step - loss: 0.0032 - acc: 0.0070 - val_loss: 0.0034 - val_acc: 0.0044\n",
      "Epoch 31/150\n",
      "41541/41541 [==============================] - 2s 38us/step - loss: 0.0032 - acc: 0.0070 - val_loss: 0.0034 - val_acc: 0.0044\n",
      "Epoch 32/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0070 - val_loss: 0.0034 - val_acc: 0.0044\n",
      "Epoch 33/150\n",
      "41541/41541 [==============================] - 2s 38us/step - loss: 0.0032 - acc: 0.0070 - val_loss: 0.0034 - val_acc: 0.0044\n",
      "Epoch 34/150\n",
      "41541/41541 [==============================] - 2s 38us/step - loss: 0.0032 - acc: 0.0070 - val_loss: 0.0034 - val_acc: 0.0044\n",
      "Epoch 35/150\n",
      "41541/41541 [==============================] - 2s 36us/step - loss: 0.0032 - acc: 0.0070 - val_loss: 0.0034 - val_acc: 0.0044\n",
      "Epoch 36/150\n",
      "41541/41541 [==============================] - 2s 37us/step - loss: 0.0032 - acc: 0.0070 - val_loss: 0.0034 - val_acc: 0.0044\n",
      "Epoch 37/150\n",
      "41541/41541 [==============================] - 2s 38us/step - loss: 0.0032 - acc: 0.0070 - val_loss: 0.0034 - val_acc: 0.0044\n",
      "Epoch 38/150\n",
      "41541/41541 [==============================] - 2s 37us/step - loss: 0.0032 - acc: 0.0070 - val_loss: 0.0034 - val_acc: 0.0044\n",
      "Epoch 39/150\n",
      "41541/41541 [==============================] - 2s 37us/step - loss: 0.0032 - acc: 0.0070 - val_loss: 0.0034 - val_acc: 0.0044\n",
      "Epoch 40/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0070 - val_loss: 0.0034 - val_acc: 0.0044\n",
      "Epoch 41/150\n",
      "41541/41541 [==============================] - 2s 37us/step - loss: 0.0032 - acc: 0.0070 - val_loss: 0.0034 - val_acc: 0.0044\n",
      "Epoch 42/150\n",
      "41541/41541 [==============================] - 2s 37us/step - loss: 0.0032 - acc: 0.0070 - val_loss: 0.0034 - val_acc: 0.0044\n",
      "Epoch 43/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0070 - val_loss: 0.0034 - val_acc: 0.0044\n",
      "Epoch 44/150\n",
      "41541/41541 [==============================] - 2s 38us/step - loss: 0.0032 - acc: 0.0070 - val_loss: 0.0034 - val_acc: 0.0044\n",
      "Epoch 45/150\n",
      "41541/41541 [==============================] - 2s 38us/step - loss: 0.0032 - acc: 0.0070 - val_loss: 0.0034 - val_acc: 0.0044\n",
      "Epoch 46/150\n",
      "41541/41541 [==============================] - 1s 36us/step - loss: 0.0032 - acc: 0.0070 - val_loss: 0.0034 - val_acc: 0.0044\n",
      "Epoch 47/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0070 - val_loss: 0.0034 - val_acc: 0.0044\n",
      "Epoch 48/150\n",
      "41541/41541 [==============================] - 2s 38us/step - loss: 0.0032 - acc: 0.0070 - val_loss: 0.0034 - val_acc: 0.0044\n",
      "Epoch 49/150\n",
      "41541/41541 [==============================] - 2s 38us/step - loss: 0.0032 - acc: 0.0070 - val_loss: 0.0042 - val_acc: 0.0044\n",
      "Epoch 50/150\n",
      "41541/41541 [==============================] - 2s 40us/step - loss: 0.0034 - acc: 0.0074 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 51/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 52/150\n",
      "41541/41541 [==============================] - 2s 41us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 53/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 54/150\n",
      "41541/41541 [==============================] - 2s 38us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 55/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 56/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 57/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 58/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 59/150\n",
      "41541/41541 [==============================] - 2s 41us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 60/150\n",
      "41541/41541 [==============================] - 2s 40us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 61/150\n",
      "41541/41541 [==============================] - 2s 42us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 62/150\n",
      "41541/41541 [==============================] - 2s 40us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 63/150\n",
      "41541/41541 [==============================] - 2s 43us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 64/150\n",
      "41541/41541 [==============================] - 2s 40us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 65/150\n",
      "41541/41541 [==============================] - 2s 40us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 66/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 67/150\n",
      "41541/41541 [==============================] - 2s 41us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 68/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 69/150\n",
      "41541/41541 [==============================] - 2s 40us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 70/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 71/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 72/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 73/150\n",
      "41541/41541 [==============================] - 2s 40us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 74/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 75/150\n",
      "41541/41541 [==============================] - 2s 40us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 76/150\n",
      "41541/41541 [==============================] - 2s 40us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 77/150\n",
      "41541/41541 [==============================] - 2s 40us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 78/150\n",
      "41541/41541 [==============================] - 2s 43us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 79/150\n",
      "41541/41541 [==============================] - 2s 40us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 80/150\n",
      "41541/41541 [==============================] - 2s 40us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 81/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 82/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 83/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 84/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 85/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 86/150\n",
      "41541/41541 [==============================] - 2s 40us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 87/150\n",
      "41541/41541 [==============================] - 2s 40us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 88/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 89/150\n",
      "41541/41541 [==============================] - 2s 40us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 90/150\n",
      "41541/41541 [==============================] - 2s 40us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 91/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 92/150\n",
      "41541/41541 [==============================] - 2s 40us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 93/150\n",
      "41541/41541 [==============================] - 2s 40us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 94/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 95/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 96/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 97/150\n",
      "41541/41541 [==============================] - 2s 40us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 98/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 99/150\n",
      "41541/41541 [==============================] - 2s 40us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 100/150\n",
      "41541/41541 [==============================] - 2s 40us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 101/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 102/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 103/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 104/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 105/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 106/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 107/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 108/150\n",
      "41541/41541 [==============================] - 2s 40us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 109/150\n",
      "41541/41541 [==============================] - 2s 40us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 110/150\n",
      "41541/41541 [==============================] - 2s 40us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 111/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 112/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 113/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 114/150\n",
      "41541/41541 [==============================] - 2s 40us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 115/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 116/150\n",
      "41541/41541 [==============================] - 2s 41us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 117/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 118/150\n",
      "41541/41541 [==============================] - 2s 40us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 119/150\n",
      "41541/41541 [==============================] - 2s 38us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 120/150\n",
      "41541/41541 [==============================] - 2s 40us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 121/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 122/150\n",
      "41541/41541 [==============================] - 2s 40us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 123/150\n",
      "41541/41541 [==============================] - 2s 41us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 124/150\n",
      "41541/41541 [==============================] - 2s 38us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 125/150\n",
      "41541/41541 [==============================] - 2s 41us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 126/150\n",
      "41541/41541 [==============================] - 2s 40us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 127/150\n",
      "41541/41541 [==============================] - 2s 41us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 128/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 129/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 130/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 131/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 132/150\n",
      "41541/41541 [==============================] - 2s 42us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 133/150\n",
      "41541/41541 [==============================] - 2s 41us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 134/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 135/150\n",
      "41541/41541 [==============================] - 2s 40us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 136/150\n",
      "41541/41541 [==============================] - 2s 40us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 137/150\n",
      "41541/41541 [==============================] - 2s 42us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 138/150\n",
      "41541/41541 [==============================] - 2s 40us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 139/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 140/150\n",
      "41541/41541 [==============================] - 2s 41us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 141/150\n",
      "41541/41541 [==============================] - 2s 40us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 142/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 143/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 144/150\n",
      "41541/41541 [==============================] - 2s 41us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 145/150\n",
      "41541/41541 [==============================] - 2s 40us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 146/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 147/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 148/150\n",
      "41541/41541 [==============================] - 2s 39us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 149/150\n",
      "41541/41541 [==============================] - 2s 38us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n",
      "Epoch 150/150\n",
      "41541/41541 [==============================] - 2s 40us/step - loss: 0.0032 - acc: 0.0078 - val_loss: 0.0034 - val_acc: 0.0057\n"
     ]
    }
   ],
   "source": [
    "from ptfind.utils import train\n",
    "\n",
    "for i in range(num_setups):\n",
    "    train(\n",
    "        aes[i],\n",
    "        data_train_norm.reshape(data_train_norm.shape[0], data_train_norm.shape[1]),\n",
    "        data_test_norm.reshape(data_test_norm.shape[0], data_test_norm.shape[1]),\n",
    "        epochs=setups['epochs'][i],\n",
    "        batch_size=256,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 8.59649\n",
      "1 10.122\n",
      "2 7.82983\n",
      "3 29.1472\n"
     ]
    }
   ],
   "source": [
    "from keras.metrics import binary_crossentropy, mse\n",
    "from ae.utils import predict\n",
    "\n",
    "predicteds = []\n",
    "losses = []\n",
    "\n",
    "for i in range(num_setups):\n",
    "    predicted, loss, _ = predict(\n",
    "        ens[i],\n",
    "        des[i],\n",
    "        data_test_norm.reshape(data_test_norm.shape[0], data_test_norm.shape[1]),\n",
    "        validator=mse\n",
    "    )\n",
    "    predicteds.append(predicted.reshape(predicted.shape[0], predicted.shape[1]))\n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIQAAANHCAYAAABHCYaiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3U+IZWe5P/rvY8c46IHCtcGQbjVgY/ODcwamSBwd5FwCrQfSAwNpL6gRQ3PARjgjzUQlo4QzuCgGpYyNiYNEyKjkNAQODhx56Wo45JhIfpRBSZ1W7CQSuAgeGp476O397d9Ode/VXWtX713784GCetd6s/ZTf3rX3t8877uquwMAAADA+njfnS4AAAAAgIMlEAIAAABYMwIhAAAAgDUjEAIAAABYMwIhAAAAgDUjEAIAAABYM3MDoaq6UFV/qqpf3+B8VdX3qmqnql6pqk+NXyYAAAAAYxnSIfSTJKdvcv6zSU5OPs4l+cH+ywIAAABgUeYGQt39yyTv3GTKmSTP93W/SvKhqrpnrAIBAAAAGNddI1zj3iRvTo13J8f+MDuxqs7lehdRjh49ev+pU6dGeHgAAGCV/PGPf9zz+Ec+8pEDrgTg8Ll8+fJb3X1s3rwxAqHa41jvNbG7N5NsJsnGxkZvb2+P8PAAALC3p59++obnvvGNbxxgJetjyPf8RnP8TAD2r6p+P2TeGHcZ201yYmp8PMmVEa4LAAAAwAKM0SG0leR8Vb2Y5MEk73b3e5aLAQAAi6MbCoBbMTcQqqoXknwmyYerajfJt5O8P0m6+4dJLib5XJKdJH9J8pVFFQsAAGMSogCwruYGQt39hTnnO8nXRqsIAAAAgIUaYw8hAAAAAFbIGHsIAQDAoTVvWZllZwCsIoEQAACsCeEVAH9jyRgAAADAmhEIAQAAAKwZS8YAAIClYmkbwOIJhAAAYAUISQAYkyVjAAAAAGtGhxAAACvrRl0zOmYWx/cc4HDQIQQAAACwZnQIAQDAgtn/B4BlIxACAACSCK4A1olACAAAWDn2MgLYH3sIAQAAAKyZQR1CVXU6yXeTHEnybHc/NXP+sST/muS/Joe+393PjlgnAAArxNIjVoEuI2CdzQ2EqupIkmeSPJRkN8mlqtrq7tdmpv6su88voEYAAIBbIpQEuLkhHUIPJNnp7jeSpKpeTHImyWwgBAAAo1mnN/Tr9LUCsByG7CF0b5I3p8a7k2OzPl9Vr1TVS1V1Yq8LVdW5qtququ2rV6/eRrkAAAAA7NeQDqHa41jPjH+e5IXu/mtV/XOS55L843v+o+7NJJtJsrGxMXsNAABWxBh7r9i/BQDunCEdQrtJpjt+jie5Mj2hu9/u7r9Ohj9Kcv845QEAAAAwtiGB0KUkJ6vqvqq6O8nZJFvTE6rqnqnhw0l+M16JAAAAAIxp7pKx7r5WVeeTvJzrt52/0N2vVtWTSba7eyvJ16vq4STXkryT5LEF1gwAAADAPgzZQyjdfTHJxZlj35r6/IkkT4xbGgAAAACLMCgQAgBgfbgFOgAcfkP2EAIAAADgENEhBAAAsAfdcsBhpkMIAAAAYM0IhAAAAADWjEAIAAAAYM0IhAAAAADWjEAIAAAAYM0IhAAAAADWjNvOs7bcRhQAgP3wehJYZQIhAIA1400sHBz/3oBlJRCCJedFBADA4eW1HnCn2EMIAAAAYM3oEBrBvFRf6n/wVul7vkq1AgDAYXCj1+B/e/29LK/RvddkkQYFQlV1Osl3kxxJ8mx3PzVz/gNJnk9yf5K3kzza3b8bt9T1tk7/0Jflax2jjoP6Wub9QQNgfSzL31FgPEKBW3MQ3w/fcw6DuYFQVR1J8kySh5LsJrlUVVvd/drUtK8m+XN3f6KqziZ5Osmjiyj4sFqnJ5RVClpWpY55htS5Kv+XhPXld/DwWobnn/08T95KHWO8qfNvAbgdy/4c5vmLMfgdvDVDOoQeSLLT3W8kSVW9mORMkulA6EyS70w+fynJ96uqurtHrJU5xvjFHuNFuX9g6+uw/P6s0hvD/T7GzeYc9M9tv9fwJnm9rUqoBLCsluU5bFVeLw6xLJ1dy/I3cFlec/K/1LzMpqoeSXK6ux+fjL+Y5MHuPj8159eTObuT8W8nc96auda5JOcmw08meX2sLwQAAACAfKy7j82bNKRDqPY4NpsiDZmT7t5MsjngMQEAAABYkCG3nd9NcmJqfDzJlRvNqaq7knwwyTtjFAgAAADAuIYEQpeSnKyq+6rq7iRnk2zNzNlK8uXJ548k+YX9gwAAAACW09wlY919rarOJ3k51287f6G7X62qJ5Nsd/dWkh8n+WlV7eR6Z9DZRRYNAAAAwO2bu6k0AAAAAIfL3CVjVXWhqv40uZPYXuerqr5XVTtV9UpVfWr8MgEAAAAYy5A9hH6S5PRNzn82ycnJx7kkP9h/WQAAAAAsytxAqLt/mZvfMexMkuf7ul8l+VBV3TNWgQAAAACMa+6m0gPcm+TNqfHu5NgfZidW1blc7yLK0aNH7z916tQIDw8AAABAkly+fPmt7j42b94YgVDtcWzPnaq7ezPJZpJsbGz09vb2CA8PAAAAQJJU1e+HzBuyh9A8u0lOTI2PJ7kywnUBAAAAWIAxAqGtJF+a3G3s00ne7e73LBcDAAAAYDnMXTJWVS8k+UySD1fVbpJvJ3l/knT3D5NcTPK5JDtJ/pLkK4sqFgAAAID9mxsIdfcX5pzvJF8brSIAAAAAFmqMJWMAAAAArBCBEAAAAMCaEQgBAAAArBmBEAAAAMCaEQgBAAAArBmBEAAAAMCamXvbeQAAYPl9/Jv/dsNzv3vqnwbPAWA9CIQAAGAFHESYIzACWB+WjAEAAACsGR1CAAAcWjpexnej76llaQCrRSAEAMDKmhdO3O5/fyvXGMOy1AHA+hAIAQDAggl8AFg2AiEAALgJYQ4Ah5FACACApbQqQcyq1AkA0wYFQlV1Osl3kxxJ8mx3PzVz/rEk/5rkvyaHvt/dz45YJwAAcEjsd+8nAPZvbiBUVUeSPJPkoSS7SS5V1VZ3vzYz9WfdfX4BNQIAAAAwoiEdQg8k2enuN5Kkql5McibJbCAEAACD6RIBgDvnfQPm3Jvkzanx7uTYrM9X1StV9VJVndjrQlV1rqq2q2r76tWrt1EuAAAAAPs1pEOo9jjWM+OfJ3mhu/9aVf+c5Lkk//ie/6h7M8lmkmxsbMxeAwAAwEbdAAdgSCC0m2S64+d4kivTE7r77anhj5I8vf/SAAAA9mbJIcD+DFkydinJyaq6r6ruTnI2ydb0hKq6Z2r4cJLfjFciAAAAAGOa2yHU3deq6nySl3P9tvMXuvvVqnoyyXZ3byX5elU9nORakneSPLbAmgEAWHKW/HCn+R0EuLkhS8bS3ReTXJw59q2pz59I8sS4pQEAAACwCEOWjAEAAABwiAiEAAAAANbMoCVjAACsjyF7r7jDEwCsNh1CAAAAAGtGhxAAwJpx9yW4TqcbsM50CAEAAACsGYEQAAAAwJoRCAEAAACsGXsIAQAA7MF+W8BhJhACADhEvIEFAIawZAwAAABgzegQAgAAuA1jdOTp6gPuFIEQAMAK8eYRVstBhEaeF4DbIRACANbekDdT3tQBq8zzCzBrUCBUVaeTfDfJkSTPdvdTM+c/kOT5JPcneTvJo939u3FLBQC4PQfxRsibLWCVjRGM7+canifh4M0NhKrqSJJnkjyUZDfJpara6u7XpqZ9Ncmfu/sTVXU2ydNJHl1EwQCw6hb5gnqMa9xKR8yqXAOA1bAsfzeE/KyDIR1CDyTZ6e43kqSqXkxyJsl0IHQmyXcmn7+U5PtVVd3dI9YKwBpb9hDlVq4BAKy2g9pQfJ1edyxLGLhOal5mU1WPJDnd3Y9Pxl9M8mB3n5+a8+vJnN3J+LeTOW/NXOtcknOT4SeTvD7WFwIAAABAPtbdx+ZNGtIhVHscm02RhsxJd28m2RzwmAAAAAAsyPsGzNlNcmJqfDzJlRvNqaq7knwwyTtjFAgAAADAuIYEQpeSnKyq+6rq7iRnk2zNzNlK8uXJ548k+YX9gwAAAACW09wlY919rarOJ3k51287f6G7X62qJ5Nsd/dWkh8n+WlV7eR6Z9DZRRYNAAAAwO2bu6k0AAAAAIfL3CVjVXWhqv40uZPYXuerqr5XVTtV9UpVfWr8MgEAAAAYy5A9hH6S5PRNzn82ycnJx7kkP9h/WQAAAAAsytxAqLt/mZvfMexMkuf7ul8l+VBV3TNWgQAAAACMa+6m0gPcm+TNqfHu5NgfZidW1blc7yLK0aNH7z916tQIDw8AAABAkly+fPmt7j42b94YgVDtcWzPnaq7ezPJZpJsbGz09vb2CA8PAAAAQJJU1e+HzBuyh9A8u0lOTI2PJ7kywnUBAAAAWIAxAqGtJF+a3G3s00ne7e73LBcDAAAAYDnMXTJWVS8k+UySD1fVbpJvJ3l/knT3D5NcTPK5JDtJ/pLkK4sqFgAAAID9mxsIdfcX5pzvJF8brSIAAAAAFmqMJWMAAAAArBCBEAAAAMCaEQgBAAAArJm5ewgBAABL4DsfvMm5dw+uDgAOBYEQAADcaWOEPQIjAG6BQAgAAPZjSBAjrAFgyQiEAABgXQimAJgQCAEAANcJjADWhkAIAABuRkgCwCEkEAIAYHXdKKwZunePsOfWzfueA7AS3nenCwAAAADgYOkQAgBgOeneAYCFEQgBAADjEeQBrASBEAAAd4a9aADgjhm0h1BVna6q16tqp6q+ucf5x6rqalX9x+Tj8fFLBQAAAGAMczuEqupIkmeSPJRkN8mlqtrq7tdmpv6su88voEYAAAAARjRkydgDSXa6+40kqaoXk5xJMhsIAQDAdfaRAYClNmTJ2L1J3pwa706Ozfp8Vb1SVS9V1Ym9LlRV56pqu6q2r169ehvlAgAAALBfQwKh2uNYz4x/nuTj3f33Sf49yXN7Xai7N7t7o7s3jh07dmuVAgAAADCKIUvGdpNMd/wcT3JlekJ3vz01/FGSp/dfGgAAS8sdwtgPvz8Ad9yQDqFLSU5W1X1VdXeSs0m2pidU1T1Tw4eT/Ga8EgEAAAAY09wOoe6+VlXnk7yc5EiSC939alU9mWS7u7eSfL2qHk5yLck7SR5bYM0AAAAA7MOQJWPp7otJLs4c+9bU508keWLc0gAAuCPcIYw7ze8gwMINWTIGAAAAwCEyqEMIAABgqczbmFqXEcBN6RACAAAAWDM6hAAAgPU0r8sI4BATCAEArBtLaQBg7QmEAACWhaAGlot/k8AhJhACAFgl896gegMLAAwgEAIAOCjCGgBgSQiEAAAAbseQkFcQDCwpgRAAwBhv6rzpA26HUAm4QwRCAMBy28+bJW+mAAD2JBACAG7fvCDmoK4BsM6E3sBtEAgBwCo6iOVLy3INAPbP8zEwQyAEwOKNseRnnRzUi3bfcwD+ZpUCo3X6+3UQ/3PmoPbRW6ef24oYFAhV1ekk301yJMmz3f3UzPkPJHk+yf1J3k7yaHf/btxSAVhry9IRo2sGgHV1EKHAnf57fhAByK1cY57D9JrioH5/BFP/v7mBUFUdSfJMkoeS7Ca5VFVb3f3a1LSvJvlzd3+iqs4meTrJo4soGIADdpj+sB7Ei6bD9MIMAIBDa0iH0ANJdrr7jSSpqheTnEkyHQidSfKdyecvJfl+VVV394i1AnCrDlOYAwAAjKbmZTZV9UiS0939+GT8xSQPdvf5qTm/nszZnYx/O5nz1sy1ziU5Nxl+MsnrY30hAAAAAORj3X1s3qQhHUK1x7HZFGnInHT3ZpLNAY8JAAAAwIK8b8Cc3SQnpsbHk1y50ZyquivJB5O8M0aBAAAAAIxrSCB0KcnJqrqvqu5OcjbJ1sycrSRfnnz+SJJf2D8IAAAAYDnNXTLW3deq6nySl3P9tvMXuvvVqnoyyXZ3byX5cZKfVtVOrncGnV1k0QAAAADcvrmbSgMAAABwuMxdMlZVF6rqT5M7ie11vqrqe1W1U1WvVNWnxi8TAAAAgLEM2UPoJ0lO3+T8Z5OcnHycS/KD/ZcFAAAAwKLMDYS6+5e5+R3DziR5vq/7VZIPVdU9YxUIAAAAwLjmbio9wL1J3pwa706O/WF2YlWdy/Uuohw9evT+U6dOjfDwAAAAACTJ5cuX3+ruY/PmjREI1R7H9typurs3k2wmycbGRm9vb4/w8AAAAAAkSVX9fsi8IXsIzbOb5MTU+HiSKyNcFwAAAIAFGCMQ2krypcndxj6d5N3ufs9yMQAAAACWw9wlY1X1QpLPJPlwVe0m+XaS9ydJd/8wycUkn0uyk+QvSb6yqGIBAAAA2L+5gVB3f2HO+U7ytdEqAgAAAGChxthUGgAADq2/e+7vbnjuP7/8nwdYCQCMRyAEAAD7MCQwmjdnjGsAwK0QCAEAsLYOU8hymL4WABZvjLuMAQAAALBCdAgBAHBo6ZoBgL0JhAAAWFk3CnyEPXsTkAHwN5aMAQAAAKwZHUIAACwl3SwHz/ccYH3oEAIAAABYMzqEAAC4I+z/s5r83AAOBx1CAAAAAGtGhxAAADAa+xABrAYdQgAAAABrRiAEAAAAsGYGBUJVdbqqXq+qnar65h7nH6uqq1X1H5OPx8cvFQAAAIAxzN1DqKqOJHkmyUNJdpNcqqqt7n5tZurPuvv8AmoEAGDF2EeGmzmIO5X5HQS4uSEdQg8k2enuN7r7v5O8mOTMYssCAAAAYFGG3GXs3iRvTo13kzy4x7zPV9U/JPmfSf6lu9+cnVBV55KcS5KPfvSjt14tAABw6A3p7jmILiOAw2xIIFR7HOuZ8c+TvNDdf62qf07yXJJ/fM9/1L2ZZDNJNjY2Zq8BAMAS8GYcAA6/IUvGdpOcmBofT3JlekJ3v93df50Mf5Tk/nHKAwAAAGBsQwKhS0lOVtV9VXV3krNJtqYnVNU9U8OHk/xmvBIBAAAAGNPcJWPdfa2qzid5OcmRJBe6+9WqejLJdndvJfl6VT2c5FqSd5I8tsCaAQAA9s3SR2CdDdlDKN19McnFmWPfmvr8iSRPjFsaAAAAAIswZMkYAAAAAIeIQAgAAABgzQxaMgYAALBubrTHUGKfIWD1CYQAANaMN7kAgCVjAAAAAGtGIAQAAACwZiwZAwAAuA2WXwKrTCAEAACwIEIjYFlZMgYAAACwZnQIAQAA3CE6iIA7RSAEAHCIeHMJAAwhEAIAWBLCHGAv854bhjx3eH4BZgmEAABWiDd1AMAYBEIAAAOMEcQIc4BlNUaXkec4WC2DAqGqOp3ku0mOJHm2u5+aOf+BJM8nuT/J20ke7e7fjVsqAMBiCHsADsaNnitvZWnbvGssC0v9Dp7v162ZGwhV1ZEkzyR5KMlukktVtdXdr01N+2qSP3f3J6rqbJKnkzy6iIIBAG6VF4gA62OMUGlVuqEOqrPrIL4fBxUGrkqgeBCGdAg9kGSnu99Ikqp6McmZJNOB0Jkk35l8/lKS71dVdXePWCsAsIYO0/8tBoB15W/18ql5mU1VPZLkdHc/Phl/McmD3X1+as6vJ3N2J+PfTua8NXOtc0nOTYafTPL6WF8IAAAAAPlYdx+bN2lIh1DtcWw2RRoyJ929mWRzwGMCAAAAsCDvGzBnN8mJqfHxJFduNKeq7krywSTvjFEgAAAAAOMaEghdSnKyqu6rqruTnE2yNTNnK8mXJ58/kuQX9g8CAAAAWE5zl4x197WqOp/k5Vy/7fyF7n61qp5Mst3dW0l+nOSnVbWT651BZxdZNAAAAAC3b+6m0gAAAAAcLnOXjFXVhar60+ROYnudr6r6XlXtVNUrVfWp8csEAAAAYCxD9hD6SZLTNzn/2SQnJx/nkvxg/2UBAAAAsChzA6Hu/mVufsewM0me7+t+leRDVXXPWAUCAAAAMK65m0oPcG+SN6fGu5Njf5idWFXncr2LKEePHr3/1KlTIzw8AAAAAEly+fLlt7r72Lx5YwRCtcexPXeq7u7NJJtJsrGx0dvb2yM8PAAAAABJUlW/HzJvyB5C8+wmOTE1Pp7kygjXBQAAAGABxgiEtpJ8aXK3sU8nebe737NcDAAAAIDlMHfJWFW9kOQzST5cVbtJvp3k/UnS3T9McjHJ55LsJPlLkq8sqlgAAAAA9m9uINTdX5hzvpN8bbSKAAAAAFioMZaMAQAAALBCBEIAAAAAa0YgBAAAALBmBEIAAAAAa0YgBAAAALBmBEIAAAAAa0YgBAAAALBmBEIAAAAAa0YgBAAAALBmBEIAAAAAa0YgBAAAALBmBEIAAAAAa0YgBAAAALBmBEIAAAAAa2ZQIFRVp6vq9araqapv7nH+saq6WlX/Mfl4fPxSAQAAABjDXfMmVNWRJM8keSjJbpJLVbXV3a/NTP1Zd59fQI0AAAAAjGhIh9ADSXa6+43u/u8kLyY5s9iyAAAAAFiUIYHQvUnenBrvTo7N+nxVvVJVL1XVib0uVFXnqmq7qravXr16G+UCAAAAsF9DAqHa41jPjH+e5OPd/fdJ/j3Jc3tdqLs3u3ujuzeOHTt2a5UCAAAAMIohgdBukumOn+NJrkxP6O63u/uvk+GPktw/TnkAAAAAjG1IIHQpycmquq+q7k5yNsnW9ISqumdq+HCS34xXIgAAAABjmnuXse6+VlXnk7yc5EiSC939alU9mWS7u7eSfL2qHk5yLck7SR5bYM0AAAAA7EN1z24HdDA2NjZ6e3v7jjw2AAAAwGFUVZe7e2PevCFLxgAAAAA4RARCAAAAAGtGIAQAAACwZgRCAAAAAGtGIAQAAACwZgRCAAAAAGtGIAQAAACwZgRCAAAAAGtGIAQAAACwZgRCAAAAAGtGIAQAAACwZgRCAAAAAGtGIAQAAACwZgRCAAAAAGtmUCBUVaer6vWq2qmqb+5x/gNV9bPJ+f+nqj4+dqEAAAAAjGNuIFRVR5I8k+SzSf5Hki9U1f+YmfbVJH/u7k8k+b+TPD12oQAAAACMY0iH0ANJdrr7je7+7yQvJjkzM+dMkucmn7+U5P+sqhqvTAAAAADGcteAOfcmeXNqvJvkwRvN6e5rVfVukv8jyVvTk6rqXJJzk+H/W1Wv307RAAAAAOzpY0MmDQmE9ur06duYk+7eTLI54DEBAAAAWJAhS8Z2k5yYGh9PcuVGc6rqriQfTPLOGAUCAAAAMK4hgdClJCer6r6qujvJ2SRbM3O2knx58vkjSX7R3e/pEAIAAADgzpu7ZGyyJ9D5JC8nOZLkQne/WlVPJtnu7q0kP07y06rayfXOoLOLLBoAAACA21caeQAAAADWy9wlY1V1oar+VFW/vsH5qqrvVdVOVb1SVZ8av0wAAAAAxjJkD6GfJDl9k/OfTXJy8nEuyQ/2XxYAAAAAizI3EOruX+bmdww7k+T5vu5XST5UVfeMVSAAAAAA45q7qfQA9yZ5c2q8Ozn2h9mJVXUu17uIcvTo0ftPnTo1wsMDh8kf//jHPY9/5CMfOeBKAAAAVs/ly5ff6u5j8+aNEQjVHsf23Km6uzeTbCbJxsZGb29vj/DwcHuefvrpG577xje+cYCVrI8h3/MbzfEzAQAAmK+qfj9k3pA9hObZTXJianw8yZURrgsAAADAAozRIbSV5HxVvZjkwSTvdvd7losBd45uKAAAAKbNDYSq6oUkn0ny4araTfLtJO9Pku7+YZKLST6XZCfJX5J8ZVHFwkESogAAAHBYzQ2EuvsLc853kq+NVhEAAAAACzXGkjHgBnQZAQAAsIwEQrAPAh8AAABWkUAISOJ27wAAAOtkjNvOAwAAALBCBEIAAAAAa8aSMWCl2LcJAABg/wRCcAjY/wcAAIBbYckYAAAAwJrRIcShZFnRnaFTCQAAYDXoEAIAAABYMzqE4A7TzQQAAMBBEwgBgwiuAAAADg+BEHCoCK4AAADms4cQAAAAwJoZ1CFUVaeTfDfJkSTPdvdTM+cfS/KvSf5rcuj73f3siHVyiOjgYNn5HQUAAA67uYFQVR1J8kySh5LsJrlUVVvd/drM1J919/kF1AgwKoEPAACw7oZ0CD2QZKe730iSqnoxyZkks4EQHJh1ekO/Tl8rAAAAB2PIHkL3Jnlzarw7OTbr81X1SlW9VFUn9rpQVZ2rqu2q2r569eptlAsAAADAfg3pEKo9jvXM+OdJXujuv1bVPyd5Lsk/vuc/6t5MspkkGxsbs9fgkLhRR8vQbhYdMQAAALBYQzqEdpNMd/wcT3JlekJ3v93df50Mf5Tk/nHKAwAAAGBsQwKhS0lOVtV9VXV3krNJtqYnVNU9U8OHk/xmvBIBAAAAGNPcJWPdfa2qzid5OddvO3+hu1+tqieTbHf3VpKvV9XDSa4leSfJYwusGQAAAIB9GLKHULr7YpKLM8e+NfX5E0meGLc0AABgTPZqBOBvBgVC8DdeRAAAAMDqG7KHEAAAAACHiA4hgNugWw4AAFhlOoQAAAAA1owOIQAAOARWqXv1RrX+rc5V+loAVpUOIQAAAIA1IxACAAAAWDMCIQAAAIA1Yw8hgAWw9wEAt8LfjTtj3l5GAIeZQAgAAEgimAJYJwIh/jf+LwkcHC+6AbgV/m4AMCaBEMCS8sIfAABYFIEQANwCQR3AzXmeBFgNAiEAmFilNzHzal2lr2Wd+LkcTkN+rn72q8nPDTjMBgVCVXU6yXeTHEnybHc/NXP+A0meT3J/kreTPNrdvxu3VPbLHzQ4fIQCt+Ygvh++5+zHKv3+zNt3cJW+lnkO09cyhmXZc9Lv4HX+3rNffn/W19xAqKqOJHkmyUNJdpNcqqqt7n5tatpXk/y5uz9RVWeTPJ3k0UUUvIzG+Ac0xpP8svxxBlbLGM8dY7woX6cX9hy8Rf6dvZVrjGGd/i0cxOufdfp+cmd47hhWh39vy21Zfn8Y15AOoQeS7HT3G0lSVS8mOZNkOhA6k+Q7k89fSvL9qqru7hFrXVn+8QCrbFWew1alzmT53xyMGcIdVBjoDcb/clA/tzEcxM9tlZ4bWD2H6fdrWZ47DtNz/rL8z4hl6ZBelp/bstSxDGpeZlNVjyQ53d2PT8ZfTPJgd5+fmvPryZzdyfi3kzlvzVzrXJJzk+Enk7w+1hcCAAAAQD544ZlZAAAgAElEQVTW3cfmTRrSIVR7HJtNkYbMSXdvJtkc8JgAAAAALMj7BszZTXJianw8yZUbzamqu5J8MMk7YxQIAAAAwLiGBEKXkpysqvuq6u4kZ5NszczZSvLlyeePJPmF/YMAAAAAltPcJWPdfa2qzid5OddvO3+hu1+tqieTbHf3VpIfJ/lpVe3kemfQ2UUWDQAAAMDtm7upNAAAAACHy9wlY1V1oar+NLmT2F7nq6q+V1U7VfVKVX1q/DIBAAAAGMuQPYR+kuT0Tc5/NsnJyce5JD/Yf1kAAAAALMrcQKi7f5mb3zHsTJLn+7pfJflQVd0zVoEAAAAAjGvuptID3Jvkzanx7uTYH2YnVtW5XO8iytGjR+8/derUCA8PAAAAQJJcvnz5re4+Nm/eGIFQ7XFsz52qu3szyWaSbGxs9Pb29ggPDwAAAECSVNXvh8wbsofQPLtJTkyNjye5MsJ1AQAAAFiAMTqEtpKcr6oXkzyY5N3ufs9yMVg2H//mv93w3O+e+qcDuwYAAAActLmBUFW9kOQzST5cVbtJvp3k/UnS3T9McjHJ55LsJPlLkq8sqlgYStgDAAAANzY3EOruL8w530m+NlpFcIgcVKh0o8f522MItwAAAJg2xpIxYB/mhTXCHAAAAMYmEGIlCUkAAADg9gmEgCTzl50BAABweIxx23kAAAAAVogOIWCQIcv0dBkBAACsBh1CAAAAAGtGhxBwYGwGDgAAsBwEQiwdoQEAAAAsliVjAAAAAGtGIAQAAACwZgRCAAAAAGtGIAQAAACwZgRCAAAAAGtGIAQAAACwZgYFQlV1uqper6qdqvrmHucfq6qrVfUfk4/Hxy8VAAAAgDHcNW9CVR1J8kySh5LsJrlUVVvd/drM1J919/kF1AgAAADAiIZ0CD2QZKe73+ju/07yYpIziy0LAAAAgEWZ2yGU5N4kb06Nd5M8uMe8z1fVPyT5n0n+pbvfnJ1QVeeSnEuSj370o7deLXDoffyb/7bn8d899U8HXAkAAMDhNaRDqPY41jPjnyf5eHf/fZJ/T/LcXhfq7s3u3ujujWPHjt1apQAAAACMYkiH0G6SE1Pj40muTE/o7renhj9K8vT+S+OwulEHSKILBAAAAA7CkA6hS0lOVtV9VXV3krNJtqYnVNU9U8OHk/xmvBIBAAAAGNPcDqHuvlZV55O8nORIkgvd/WpVPZlku7u3kny9qh5Oci3JO0keW2DNwBrTYQYAALB/Q5aMpbsvJrk4c+xbU58/keSJcUsDWAyhEgAAsO4GBUKsD3d4AgAAgMNPIMQt0VnBshvjd9TvOQAAcNgJhABug9AIAABYZQIhRmfZGQAAACy3IbedBwAAAOAQ0SG0RixxAQAAABKBEMAdI6QFAADuFIHQIWLvHlgewh4AAGCZCYSWxLw3j95cwvrx7x4AAFgUgdAIhDnAneL5BwAAuB3uMgYAAACwZnQIAaw5+48BAMD6EQgBsHBDlq4JpgAA4OAIhAC4qWUJc+yHBAAA4xkUCFXV6STfTXIkybPd/dTM+Q8keT7J/UneTvJod/9u3FIBYLH2E35NzwEAgGU3NxCqqiNJnknyUJLdJJeqaqu7X5ua9tUkf+7uT1TV2SRPJ3l0EQUDwF6WJcwRGAEAvNe8jvJl6UpfJ0M6hB5IstPdbyRJVb2Y5EyS6UDoTJLvTD5/Kcn3q6q6u0esFQAOhXkveMYItwRTAHBjqxIsHMRrhjEsy+uOZaljVdS8zKaqHklyursfn4y/mOTB7j4/NefXkzm7k/FvJ3PemrnWuSTnJsNPJnl9rC8EAAAAgHysu4/NmzSkQ6j2ODabIg2Zk+7eTLI54DEBAAAAWJD3DZizm+TE1Ph4kis3mlNVdyX5YJJ3xigQAAAAgHENCYQuJTlZVfdV1d1JzibZmpmzleTLk88fSfIL+wcBAAAALKe5S8a6+1pVnU/ycq7fdv5Cd79aVU8m2e7urSQ/TvLTqtrJ9c6gs4ssGgAAAIDbN3dTaQAAAAAOl7lLxqrqQlX9aXInsb3OV1V9r6p2quqVqvrU+GUCAAAAMJYhewj9JMnpm5z/bJKTk49zSX6w/7IAAAAAWJS5gVB3/zI3v2PYmSTP93W/SvKhqrpnrAIBAAAAGNfcTaUHuDfJm1Pj3cmxP8xOrKpzud5FlKNHj95/6tSpER4eAAAAgCS5fPnyW919bN68MQKh2uPYnjtVd/dmks0k2djY6O3t7REeHgAAAIAkqarfD5k3ZA+heXaTnJgaH09yZYTrAgAAALAAYwRCW0m+NLnb2KeTvNvd71kuBgAAAMBymLtkrKpeSPKZJB+uqt0k307y/iTp7h8muZjkc0l2kvwlyVcWVSwAAAAA+zc3EOruL8w530m+NlpFAAAAACzUGEvGAAAAAFghAiEAAACANSMQAgAAAFgzAiEAAACANSMQAgAAAFgzAiEAAACANSMQAgAAAFgzd93pAoAD8J0P3uTcuwdXBwAAAEtBIAT7MS9oGRLELPIatxL2LMs1AAAAWDiBENyIrpr/ne8HAADAoSEQYn0JOAAAAFhTAiEOJ2HPcvJzAQAAWAruMgYAAACwZnQIsZp0mgAAAMBtGxQIVdXpJN9NciTJs9391Mz5x5L8a5L/mhz6fnc/O2KdrBNhDwAAACzU3ECoqo4keSbJQ0l2k1yqqq3ufm1m6s+6+/wCagQAAABgREM6hB5IstPdbyRJVb2Y5EyS2UAIhtEBxM3c6PfD7wYAAMBohgRC9yZ5c2q8m+TBPeZ9vqr+Icn/TPIv3f3m7ISqOpfkXJJ89KMfvfVqAQSKAAAA+zbkLmO1x7GeGf88yce7+++T/HuS5/a6UHdvdvdGd28cO3bs1ioFAAAAYBRDOoR2k5yYGh9PcmV6Qne/PTX8UZKn918awG0Y0kGkywgAAFhzQwKhS0lOVtV9uX4XsbNJ/q/pCVV1T3f/YTJ8OMlvRq2S5eGNNAAAAKy8uYFQd1+rqvNJXs71285f6O5Xq+rJJNvdvZXk61X1cJJrSd5J8tgCa2bZ2RSYVSf4BAAADrkhHULp7otJLs4c+9bU508keWLc0gAAAABYhEGBEGtEdw8Mo4sIAABYYUPuMgYAAADAISIQAgAAAFgzlowBLIIlZQAAwBITCK0Tb1ABAACAWDIGAAAAsHZ0CAHcKbr2AACAO0SHEAAAAMCa0SF0mNyo20CnAawmHUQAAMCCCIRWhTeGAAAAwEgEQgCrTFgMAADcBoEQwGEmMAIAAPYgEFoW3rQBAAAAB0QgNAZhDrDK5m1IP+Q5boxrAAAAB2ZQIFRVp5N8N8mRJM9291Mz5z+Q5Pkk9yd5O8mj3f27cUtdYd4IAcy331DJcy0AAAw2NxCqqiNJnknyUJLdJJeqaqu7X5ua9tUkf+7uT1TV2SRPJ3l0EQUDwG0TKgGLsCzPHctSBwArYUiH0ANJdrr7jSSpqheTnEkyHQidSfKdyecvJfl+VVV394i1AsCdN0aotOzXOOjlgstwjTG+52O40z/7Ma7hZ3+DeStSBwBro+ZlNlX1SJLT3f34ZPzFJA929/mpOb+ezNmdjH87mfPWzLXOJTk3GX4yyetjfSEAAAAA5GPdfWzepCEdQrXHsdkUacicdPdmks0BjwkAAADAgrxvwJzdJCemxseTXLnRnKq6K8kHk7wzRoEAAAAAjGtIIHQpycmquq+q7k5yNsnWzJytJF+efP5Ikl/YPwgAAABgOc1dMtbd16rqfJKXc/228xe6+9WqejLJdndvJflxkp9W1U6udwadXWTRAAAAANy+uZtKAwAAAHC4zF0yVlUXqupPkzuJ7XW+qup7VbVTVa9U1afGLxMAAACAsQzZQ+gnSU7f5Pxnk5ycfJxL8oP9lwUAAADAoswNhLr7l7n5HcPOJHm+r/tVkg9V1T1jFQgAAADAuOZuKj3AvUnenBrvTo79YXZiVZ3L9S6iHD169P5Tp06N8PAAAAAAJMnly5ff6u5j8+aNEQjVHsf23Km6uzeTbCbJxsZGb29vj/DwAAAAACRJVf1+yLwhewjNs5vkxNT4eJIrI1wXAAAAgAUYIxDaSvKlyd3GPp3k3e5+z3IxAAAAAJbD3CVjVfVCks8k+XBV7Sb5dpL3J0l3/zDJxSSfS7KT5C9JvrKoYgEAAADYv7mBUHd/Yc75TvK10SoCbtnfPfd3ex7/zy//503PT88BAABgfYyxZAwAAACAFTLGXcaAQ2CMLqN51wAAAGA5CIRgyR2m5V6H6WsBAABYZZaMAQAAAKwZHUIcSmN0ouhmAQAA4LASCAFLxT5EAAAAiycQgjtMJxIAAAAHTSDESlqWJWHzriHsAQAAYBnZVBoAAABgzQiEAAAAANaMQAgAAABgzdhDCFgp9mUCAADYP4EQS8cbfvbD7w8AAMB8AiFg7QiNAACAdTdoD6GqOl1Vr1fVTlV9c4/zj1XV1ar6j8nH4+OXCgAAAMAY5nYIVdWRJM8keSjJbpJLVbXV3a/NTP1Zd59fQI0AAAAAjGhIh9ADSXa6+43u/u8kLyY5s9iyAAAAAFiUIYHQvUnenBrvTo7N+nxVvVJVL1XVib0uVFXnqmq7qravXr16G+UCAAAAsF9DAqHa41jPjH+e5OPd/fdJ/j3Jc3tdqLs3u3ujuzeOHTt2a5UCAAAAMIohgdBukumOn+NJrkxP6O63u/uvk+GPktw/TnkA8P+1dwchkp3l3sD/jzPGxSwiXGcRMoMJODgIunCa6FK4BCZ+kFkYyLjQRAy9cXB7czefkpVZXRSD0upg4sIEsmr5AgFx4crL9IBEEwm0QUkzgpNEAh+CMvB8i6nLV3Z6UifTp3qq+/x+0FDvOQ/nPDVVXan+5z3vAQAAxjYkELqS5ExV3V9VdyW5mGRzvqCq7pkbPpzkD+O1CAAAAMCYFt5lrLtvVNWlJC8nOZbkcne/WlVPJdnq7s0k36yqh5PcSPJOkseX2DMAAAAA+7AwEEqS7n4pyUu7tv3vucf/meQ/x20N4M749LOfvuW+3z32uwPsBAAAYDmGXDIGAAAAwBEyaIYQjMnsCwAAALizzBACAAAAmBiBEAAAAMDECIQAAAAAJsYaQgC3wVpYAADAYSYQ4gPxRzAAAAAcfgIhRner0EhgBAAAAKtBIMS/EOYAAADA0WdRaQAAAICJEQgBAAAATIxLxlbEosWaLeYMh4vf2X/l3wMAAFaLQGhC/EEGq2WMIHhVwuQx1h+zhhkAABwcgdAIViVo8ccUcDsWfXas+mfcQfcBAABHwaBAqKrOJ/lukmNJftzd39m1/yNJnktyLsnbSR7t7j+N2+rh5Y8YgOU7TDOqAIDDzXeG8e3nu9yq/Y/Mw2JhIFRVx5I8k+TBJDtJrlTVZne/Nlf29SR/6+5PVNXFJE8neXQZDQPAnSRUmi6vLcDyHVQocBDBwlFaHmAMq3JFy6r0sQqGzBB6IMl2d7+RJFX1fJILSeYDoQtJvj17/GKS71dVdXeP2CsAHAkH8eVtjC/Dh8l+v9gfxBf/g+pjiFXv4yD/IOPomtJrf1CfP8s8xlF7TVbJqrz2rJ5alNlU1SNJznf3E7PxV5J8rrsvzdX8flazMxv/cVbz1q5jrSdZnw0/meT1sZ4IAAAAAPl4d59cVDRkhlDtsW13ijSkJt29kWRjwDkBAAAAWJIPDajZSXJ6bnwqybVb1VTV8SR3J3lnjAYBAAAAGNeQQOhKkjNVdX9V3ZXkYpLNXTWbSR6bPX4kya+sHwQAAACwmhZeMtbdN6rqUpKXc/O285e7+9WqeirJVndvJvlJkp9V1XZuzgy6uMymAQAAALh9CxeVBgAAAOBoWXjJWFVdrqq/zu4kttf+qqrvVdV2Vb1SVZ8dv00AAAAAxjJkDaGfJjn/PvsfSnJm9rOe5Af7bwsAAACAZVkYCHX3r/P+dwy7kOS5vuk3ST5aVfeM1SAAAAAA41q4qPQA9yZ5c268M9v2l92FVbWem7OIcuLEiXNnz54d4fQAAAAAJMnVq1ff6u6Ti+rGCIRqj217rlTd3RtJNpJkbW2tt7a2Rjg9AAAAAElSVX8eUjdkDaFFdpKcnhufSnJthOMCAAAAsARjBEKbSb46u9vY55O8293vuVwMAAAAgNWw8JKxqvp5ki8k+VhV7ST5VpIPJ0l3/zDJS0m+mGQ7yd+TfG1ZzQIAAACwfwsDoe7+8oL9neQbo3UEAAAAwFKNcckYAAAAAIeIQAgAAABgYgRCAAAAABMjEAIAAACYGIEQAAAAwMQIhAAAAAAmRiAEAAAAMDECIQAAAICJEQgBAAAATIxACAAAAGBiBEIAAAAAEyMQAgAAAJgYgRAAAADAxAiEAAAAACZmUCBUVeer6vWq2q6qJ/fY/3hVXa+q385+nhi/VQAAAADGcHxRQVUdS/JMkgeT7CS5UlWb3f3artIXuvvSEnoEAAAAYERDZgg9kGS7u9/o7n8meT7JheW2BQAAAMCyDAmE7k3y5tx4Z7Ztty9V1StV9WJVnd7rQFW1XlVbVbV1/fr122gXAAAAgP0aEgjVHtt61/gXSe7r7s8k+WWSZ/c6UHdvdPdad6+dPHnyg3UKAAAAwCiGBEI7SeZn/JxKcm2+oLvf7u5/zIY/SnJunPYAAAAAGNuQQOhKkjNVdX9V3ZXkYpLN+YKqumdu+HCSP4zXIgAAAABjWniXse6+UVWXkryc5FiSy939alU9lWSruzeTfLOqHk5yI8k7SR5fYs8AAAAA7EN1714O6GCsra311tbWHTk3AAAAwFFUVVe7e21R3ZBLxgAAAAA4QgRCAAAAABMjEAIAAACYGIEQAAAAwMQIhAAAAAAmRiAEAAAAMDECIQAAAICJEQgBAAAATIxACAAAAGBiBEIAAAAAEyMQAgAAAJgYgRAAAADAxAiEAAAAACZGIAQAAAAwMYMCoao6X1WvV9V2VT25x/6PVNULs/3/XVX3jd0oAAAAAONYGAhV1bEkzyR5KMmnkny5qj61q+zrSf7W3Z9I8l9Jnh67UQAAAADGMWSG0ANJtrv7je7+Z5Lnk1zYVXMhybOzxy8m+feqqvHaBAAAAGAsxwfU3JvkzbnxTpLP3aqmu29U1btJ/i3JW/NFVbWeZH02/L9V9frtNA0AAADAnj4+pGhIILTXTJ++jZp090aSjQHnBAAAAGBJhlwytpPk9Nz4VJJrt6qpquNJ7k7yzhgNAgAAADCuIYHQlSRnqur+qrorycUkm7tqNpM8Nnv8SJJfdfd7ZggBAAAAcOctvGRstibQpSQvJzmW5HJ3v1pVTyXZ6u7NJD9J8rOq2s7NmUEXl9k0AAAAALevTOQBAAAAmJaFl4xV1eWq+mtV/f4W+6uqvldV21X1SlV9dvw2AQAAABjLkDWEfprk/PvsfyjJmdnPepIf7L8tAAAAAJZlYSDU3b/O+98x7EKS5/qm3yT5aFXdM1aDAAAAAIxr4aLSA9yb5M258c5s2192F1bVem7OIsqJEyfOnT17doTTAwAAAJAkV69efau7Ty6qGyMQqj227blSdXdvJNlIkrW1td7a2hrh9AAAAAAkSVX9eUjdkDWEFtlJcnpufCrJtRGOCwAAAMASjBEIbSb56uxuY59P8m53v+dyMQAAAABWw8JLxqrq50m+kORjVbWT5FtJPpwk3f3DJC8l+WKS7SR/T/K1ZTULAAAAwP4tDIS6+8sL9neSb4zWEQAAAABLNcYlYwAAAAAcIgIhAAAAgIkRCAEAAABMjEAIAAAAYGIEQgAAAAATIxACAAAAmBiBEAAAAMDECIQAAAAAJkYgBAAAADAxAiEAAACAiREIAQAAAEyMQAgAAABgYgRCAAAAABMjEAIAAACYmEGBUFWdr6rXq2q7qp7cY//jVXW9qn47+3li/FYBAAAAGMPxRQVVdSzJM0keTLKT5EpVbXb3a7tKX+juS0voEQAAAIARDZkh9ECS7e5+o7v/meT5JBeW2xYAAAAAyzIkELo3yZtz453Ztt2+VFWvVNWLVXV6rwNV1XpVbVXV1vXr12+jXQAAAAD2a0ggVHts613jXyS5r7s/k+SXSZ7d60DdvdHda929dvLkyQ/WKQAAAACjGBII7SSZn/FzKsm1+YLufru7/zEb/ijJuXHaAwAAAGBsQwKhK0nOVNX9VXVXkotJNucLquqeueHDSf4wXosAAAAAjGnhXca6+0ZVXUrycpJjSS5396tV9VSSre7eTPLNqno4yY0k7yR5fIk9AwAAALAP1b17OaCDsba21ltbW3fk3MB7Pf3003tu/4//+I8D7gQAAIDbVVVXu3ttUd2QS8YAAAAAOEIEQgAAAAATIxACAAAAmJiFi0oDrJJbrXWUWO8IAABgKIEQTMBhClEsbg0AALB8LhkDAAAAmBiBEAAAAMDECIQAAAAAJsYaQrDiVmX9n1Xp4yBM6bkCAADTJBCCI8BCzAAAAHwQLhkDAAAAmBgzhIAD41IsAACA1SAQgjtMSAIAAMBBEwitCKHA0eR1PboOy2t7WPoEAAAO1qBAqKrOJ/lukmNJftzd39m1/yNJnktyLsnbSR7t7j+N2+rqOog/uA7TH3WLFjg+Sv9eh+l1OQirsLj1kNfkKL1uU3guh+15HCVH6f0FAMC/WhgIVdWxJM8keTDJTpIrVbXZ3a/NlX09yd+6+xNVdTHJ00keXUbDh9GdDieO4pf2oxQqMV2L3mM+O1i2MV577x8AgMNpyAyhB5Jsd/cbSVJVzye5kGQ+ELqQ5Nuzxy8m+X5VVXf3iL2yT/uZOWF2D3wwR+n9tSqfHWMEaKvyGXYQz2VV3oNjvH8OwmF6/xzEeQ7q9/6wfO9Yld/ZVT/GQb/2q3CMO/1vfhiPcRBW5bVfFavyXFbhd3bIMaakFmU2VfVIkvPd/cRs/JUkn+vuS3M1v5/V7MzGf5zVvLXrWOtJ1mfDTyZ5fawnAgAAAEA+3t0nFxUNmSFUe2zbnSINqUl3byTZGHBOAAAAAJbkQwNqdpKcnhufSnLtVjVVdTzJ3UneGaNBAAAAAMY1JBC6kuRMVd1fVXcluZhkc1fNZpLHZo8fSfIr6wcBAAAArKaFl4x1942qupTk5dy87fzl7n61qp5KstXdm0l+kuRnVbWdmzODLi6zaQAAAABu38JFpQEAAAA4WhZeMlZVl6vqr7M7ie21v6rqe1W1XVWvVNVnx28TAAAAgLEMWUPop0nOv8/+h5Kcmf2sJ/nB/tsCAAAAYFkWBkLd/eu8/x3DLiR5rm/6TZKPVtU9YzUIAAAAwLgWLio9wL1J3pwb78y2/WV3YVWt5+Ysopw4ceLc2bNnRzg9AAAAAEly9erVt7r75KK6MQKh2mPbnitVd/dGko0kWVtb662trRFODwAAAECSVNWfh9QNWUNokZ0kp+fGp5JcG+G4AAAAACzBGIHQZpKvzu429vkk73b3ey4XAwAAAGA1LLxkrKp+nuQLST5WVTtJvpXkw0nS3T9M8lKSLybZTvL3JF9bVrMAAAAA7N/CQKi7v7xgfyf5xmgdAQAAALBUY1wyBgAAAMAhIhACAAAAmBiBEAAAAMDECIQAAAAAJkYgBAAAADAxAiEAAACAiREIAQAAAEyMQAgAAABgYgRCAAAAABMjEAIAAACYGIEQAAAAwMQIhAAAAAAmRiAEAAAAMDECIQAAAICJGRQIVdX5qnq9qrar6sk99j9eVder6reznyfGbxUAAACAMRxfVFBVx5I8k+TBJDtJrlTVZne/tqv0he6+tIQeAQAAABjRkBlCDyTZ7u43uvufSZ5PcmG5bQEAAACwLEMCoXuTvDk33plt2+1LVfVKVb1YVaf3OlBVrVfVVlVtXb9+/TbaBQAAAGC/hgRCtce23jX+RZL7uvszSX6Z5Nm9DtTdG9291t1rJ0+e/GCdAgAAADCKIYHQTpL5GT+nklybL+jut7v7H7Phj5KcG6c9AAAAAMY2JBC6kuRMVd1fVXcluZhkc76gqu6ZGz6c5A/jtQgAAADAmBbeZay7b1TVpSQvJzmW5HJ3v1pVTyXZ6u7NJN+sqoeT3EjyTpLHl9gzAAAAAPtQ3buXAzoYa2trvbW1dUfODQAAAHAUVdXV7l5bVDfkkjEAAAAAjhCBEAAAAMDECIQAAAAAJkYgBAAAADAxAiEAAACAiREIAQAAAEzM8TvdALAa7nvy/+y5/U/f+V/vu39Izf/sBwAAYDUIhOAIGCPMOQir0gcAAMDUCYSAlWKWEQAAwPIJhGDFmVXzr/x7AAAA7J9FpQEAAAAmxgwhuMPMeBmXf08AAIDFBELA5AiNAACAqRMIwS3s5zbr/1MjeDicvG4AAMBRNygQqqrzSb6b5FiSH3f3d3bt/0iS55KcS/J2kke7+0/jtrq6/PE4roMKYrxu7MeqvAe9jwEAgNuxMBCqqmNJnknyYJKdJFeqarO7X5sr+3qSv3X3J6rqYpKnkzy6jIYPI+HEv5rSc4X9OKjA6FY1U/x8AgBgOXznXD1DZgg9kGS7u99Ikqp6PsmFJPOB0IUk3549fjHJ96uqurtH7HXSDuqPuoM4BnD0rMLnz6rMLjwKx/DfDQCOOt87Dv4YY/C9Y1y1KLOpqkeSnO/uJ2bjryT5XHdfmqv5/axmZzb+46zmrV3HWk+yPht+MsnrYz0RAAAAAPLx7j65qGjIDKHaY9vuFGlITbp7I8nGgHMCAAAAsCQfGlCzk+T03PhUkmu3qqmq40nuTvLOGA0CAAAAMK4hgdCVJGeq6v6quivJxSSbu2o2kzw2e/xIkl9ZPwgAAABgNS28ZKy7b1TVpSQv5+Zt5y9396tV9VSSre7eTPKTJD+rqu3cnBl0cZlNAwAAAHD7Fi4qDQAAAMDRsvCSsaq6XFV/nd1JbK/9VVXfq6rtqnqlqj47fpsAAAAAjGXIGkI/TXL+ffY/lOTM7Gc9yQ/23xYAAAAAy7IwEOruXxU3cy0AAA5dSURBVOf97xh2IclzfdNvkny0qu4Zq0EAAAAAxrVwUekB7k3y5tx4Z7btL7sLq2o9N2cR5cSJE+fOnj07wukBAAAASJKrV6++1d0nF9WNEQjVHtv2XKm6uzeSbCTJ2tpab21tjXB6AAAAAJKkqv48pG7IGkKL7CQ5PTc+leTaCMcFAAAAYAnGCIQ2k3x1drexzyd5t7vfc7kYAAAAAKth4SVjVfXzJF9I8rGq2knyrSQfTpLu/mGSl5J8Mcl2kr8n+dqymgUAAABg/xYGQt395QX7O8k3RusIAAAAgKUa45IxAAAAAA4RgRAAAADAxAiEAAAAACZGIAQAAAAwMQIhAAAAgIkRCAEAAABMjEAIAAAAYGIEQgAAAAATIxACAAAAmBiBEAAAAMDECIQAAAAAJkYgBAAAADAxAiEAAACAiREIAQAAAEzMoECoqs5X1etVtV1VT+6x//Gqul5Vv539PDF+qwAAAACM4fiigqo6luSZJA8m2Ulypao2u/u1XaUvdPelJfQIAAAAwIiGzBB6IMl2d7/R3f9M8nySC8ttCwAAAIBlGRII3Zvkzbnxzmzbbl+qqleq6sWqOr3Xgapqvaq2qmrr+vXrt9EuAAAAAPs1JBCqPbb1rvEvktzX3Z9J8sskz+51oO7e6O617l47efLkB+sUAAAAgFEMCYR2kszP+DmV5Np8QXe/3d3/mA1/lOTcOO0BAAAAMLYhgdCVJGeq6v6quivJxSSb8wVVdc/c8OEkfxivRQAAAADGtPAuY919o6ouJXk5ybEkl7v71ap6KslWd28m+WZVPZzkRpJ3kjy+xJ4BAAAA2Ifq3r0c0MFYW1vrra2tO3JuAAAAgKOoqq5299qiuiGXjAEAAABwhAiEAAAAACZGIAQAAAAwMQIhAAAAgIkRCAEAAABMjEAIAAAAYGIEQgAAAAATIxACAAAAmJjjd7oBYEV8++5bbH/3/ffP1wAAAHAoCIRg1Q0JYlYlzFmFPu70cx37PAAAAEsgEII7TbDwrw4iVFp0jIM4BwAAwB0kEIL9OIhggaPL+wMAALhDBEJwK/5Y507zHgQAAJZEIMR0+WObo8D7GAAAuA2DAqGqOp/ku0mOJflxd39n1/6PJHkuybkkbyd5tLv/NG6r8AH4IxluGmNR8v2c54Os/TRGHwAAwCALA6GqOpbkmSQPJtlJcqWqNrv7tbmyryf5W3d/oqouJnk6yaPLaJgjYIx1dwQ+cHBW5fftID47VuW5AgDAkg2ZIfRAku3ufiNJqur5JBeSzAdCF5J8e/b4xSTfr6rq7h6xV/broG5f7v/yA0fZqgRTyzzGmJ/5h+UYwsB/dVhetzGOcad/3w76GAAwU4sym6p6JMn57n5iNv5Kks9196W5mt/PanZm4z/Oat7adaz1JOuz4SeTvD7WEwEAAAAgH+/uk4uKhswQqj227U6RhtSkuzeSbAw4JwAAAABL8qEBNTtJTs+NTyW5dquaqjqe5O4k74zRIAAAAADjGhIIXUlypqrur6q7klxMsrmrZjPJY7PHjyT5lfWDAAAAAFbTwkvGuvtGVV1K8nJu3nb+cne/WlVPJdnq7s0kP0nys6razs2ZQReX2TQAAAAAt2/hotIAAAAAHC0LLxmrqstV9dfZncT22l9V9b2q2q6qV6rqs+O3CQAAAMBYhqwh9NMk599n/0NJzsx+1pP8YP9tAQAAALAsCwOh7v513v+OYReSPNc3/SbJR6vqnrEaBAAAAGBcCxeVHuDeJG/OjXdm2/6yu7Cq1nNzFlFOnDhx7uzZsyOcHgAAAIAkuXr16lvdfXJR3RiBUO2xbc+Vqrt7I8lGkqytrfXW1tYIpwcAAAAgSarqz0PqhqwhtMhOktNz41NJro1wXAAAAACWYIxAaDPJV2d3G/t8kne7+z2XiwEAAACwGhZeMlZVP0/yhSQfq6qdJN9K8uEk6e4fJnkpyReTbCf5e5KvLatZAAAAAPZvYSDU3V9esL+TfGO0jgAAAABYqjEuGQMAAADgEBEIAQAAAEyMQAgAAABgYgRCAAAAABMjEAIAAACYGIEQAAAAwMQIhAAAAAAmRiAEAAAAMDECIQAAAICJEQgBAAAATIxACAAAAGBiBEIAAAAAEyMQAgAAAJgYgRAAAADAxAwKhKrqfFW9XlXbVfXkHvsfr6rrVfXb2c8T47cKAAAAwBiOLyqoqmNJnknyYJKdJFeqarO7X9tV+kJ3X1pCjwAAAACMaMgMoQeSbHf3G939zyTPJ7mw3LYAAAAAWJYhgdC9Sd6cG+/Mtu32pap6paperKrTex2oqtaraquqtq5fv34b7QIAAACwX0MCodpjW+8a/yLJfd39mSS/TPLsXgfq7o3uXuvutZMnT36wTgEAAAAYxZBAaCfJ/IyfU0muzRd099vd/Y/Z8EdJzo3THgAAAABjGxIIXUlypqrur6q7klxMsjlfUFX3zA0fTvKH8VoEAAAAYEwL7zLW3Teq6lKSl5McS3K5u1+tqqeSbHX3ZpJvVtXDSW4keSfJ40vsGQAAAIB9qO7dywEdjLW1td7a2roj5wYAAAA4iqrqanevLaobcskYAAAAAEeIQAgAAABgYgRCAAAAABMjEAIAAACYGIEQAAAAwMQIhAAAAAAmRiAEAAAAMDHH73QDwP59+tlP77n9d4/97n33D6n5IMcYw6I+AAAA2D+BEHCoHFQwBQAAcJQJhIDRrMLsHoERAADAYgIh4MAIawAAAFaDQAhWnBAFAACAsQmEgMkRsgEAAFPntvMAAAAAEzNohlBVnU/y3STHkvy4u7+za/9HkjyX5FySt5M82t1/GrdVOJrMVgEAAOCgLQyEqupYkmeSPJhkJ8mVqtrs7tfmyr6e5G/d/Ymqupjk6SSPLqNhGGJIyLKo5qCOweoZ47WfmlW4wxwAADDckBlCDyTZ7u43kqSqnk9yIcl8IHQhybdnj19M8v2qqu7uEXvliDiIIAbutMMUSi4Kc8b4fTuIPoS43Gl3+nd2vma/Dup3YYzPH4H0/+cz7F95/4xvVb53rMJnx6p871iV//asyuvm9/6DqUWZTVU9kuR8dz8xG38lyee6+9Jcze9nNTuz8R9nNW/tOtZ6kvXZ8JNJXh/riQAAAACQj3f3yUVFQ2YI1R7bdqdIQ2rS3RtJNgacEwAAAIAlGXKXsZ0kp+fGp5Jcu1VNVR1PcneSd8ZoEAAAAIBxDQmEriQ5U1X3V9VdSS4m2dxVs5nksdnjR5L8yvpBAAAAAKtp4SVj3X2jqi4leTk3bzt/ubtfraqnkmx192aSnyT5WVVt5+bMoIvLbBoAAACA27dwUWkAAAAAjpaFl4xV1eWq+uvsTmJ77a+q+l5VbVfVK1X12fHbBAAAAGAsQ9YQ+mmS8++z/6EkZ2Y/60l+sP+2AAAAAFiWhYFQd/8673/HsAtJnuubfpPko1V1z1gNAgAAADCuhYtKD3BvkjfnxjuzbX/ZXVhV67k5iygnTpw4d/bs2RFODwAAAECSXL169a3uPrmoboxAqPbYtudK1d29kWQjSdbW1npra2uE0wMAAACQJFX15yF1Q9YQWmQnyem58akk10Y4LgAAAABLMEYgtJnkq7O7jX0+ybvd/Z7LxQAAAABYDQsvGauqnyf5QpKPVdVOkm8l+XCSdPcPk7yU5ItJtpP8PcnXltUsAAAAAPu3MBDq7i8v2N9JvjFaRwAAAAAs1RiXjAEAAABwiAiEAAAAACZGIAQAAAAwMQIhAAAAgIkRCAEAAABMjEAIAAAAYGIEQgAAAAATIxACAAAAmBiBEAAAAMDECIQAAAAAJkYgBAAAADAxAiEAAACAiREIAQAAAEyMQAgAAABgYgYFQlV1vqper6rtqnpyj/2PV9X1qvrt7OeJ8VsFAAAAYAzHFxVU1bEkzyR5MMlOkitVtdndr+0qfaG7Ly2hRwAAAABGNGSG0ANJtrv7je7+Z5Lnk1xYblsAAAAALMuQQOjeJG/OjXdm23b7UlW9UlUvVtXpvQ5UVetVtVVVW9evX7+NdgEAAADYryGBUO2xrXeNf5Hkvu7+TJJfJnl2rwN190Z3r3X32smTJz9YpwAAAACMYkggtJNkfsbPqSTX5gu6++3u/sds+KMk58ZpDwAAAICxDQmEriQ5U1X3V9VdSS4m2ZwvqKp75oYPJ/nDeC0CAAAAMKaFdxnr7htVdSnJy0mOJbnc3a9W1VNJtrp7M8k3q+rhJDeSvJPk8SX2DAAAAMA+VPfu5YAOxtraWm9tbd2RcwMAAAAcRVV1tbvXFtUNuWQMAAAAgCNEIAQAAAAwMQIhAAAAgIkRCAEAAABMjEAIAAAAYGIEQgAAAAATIxACAAAAmBiBEAAAAMDECIQAAAAAJkYgBAAAADAxAiEAAACAiREIAQAAAEyMQAgAAABgYgRCAAAAABMzKBCqqvNV9XpVbVfVk3vs/0hVvTDb/99Vdd/YjQIAAAAwjoWBUFUdS/JMkoeSfCrJl6vqU7vKvp7kb939iST/leTpsRsFAAAAYBxDZgg9kGS7u9/o7n8meT7JhV01F5I8O3v8YpJ/r6oar00AAAAAxnJ8QM29Sd6cG+8k+dytarr7RlW9m+Tfkrw1X1RV60nWZ8P/W1Wv307TAAAAAOzp40OKhgRCe8306duoSXdvJNkYcE4AAAAAlmTIJWM7SU7PjU8luXarmqo6nuTuJO+M0SAAAAAA4xoSCF1Jcqaq7q+qu5JcTLK5q2YzyWOzx48k+VV3v2eGEAAAAAB33sJLxmZrAl1K8nKSY0kud/erVfVUkq3u3kzykyQ/q6rt3JwZdHGZTQMAAABw+8pEHgAAAIBpGXLJGAAAAABHiEAIAAAAYGIEQgAAAAATIxACAAAAmBiBEAAAAMDECIQAAAAAJkYgBAAAADAx/w/9fZu2kaSOKwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x1080 with 15 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cmap = plt.get_cmap('tab10')\n",
    "\n",
    "n = 3\n",
    "offset = 6337\n",
    "\n",
    "ymax = 1.0\n",
    "\n",
    "plt.figure(figsize=(20, n * (num_setups + 1)))\n",
    "for i in range(n):\n",
    "    k = i + offset\n",
    "    \n",
    "    # display original\n",
    "    ax = plt.subplot(n * (num_setups + 1), 1, i * (num_setups + 1) + 1)\n",
    "    ax.set_facecolor('#ffffff')\n",
    "    plt.bar(np.arange(data_test_norm[k].size), data_test_norm[k], color='#888888')\n",
    "    plt.ylim(0, ymax)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    \n",
    "    for j in range(num_setups):\n",
    "        # display reconstruction\n",
    "        ax = plt.subplot(n * (num_setups + 1), 1, i * (num_setups + 1) + j + 2)\n",
    "        plt.bar(np.arange(predicteds[j][k].size), predicteds[j][k], color=cmap(j))\n",
    "        plt.ylim(0, ymax)\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
