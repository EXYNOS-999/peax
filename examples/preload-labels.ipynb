{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preload Labels for 3KB Windows\n",
    "\n",
    "In this notebook we're using existing peak calls for **Encode e11.5's face and hindbrain** dataset and search for differentially expressed peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import bbi\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import sqlite3\n",
    "import sys\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Configurations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_PRELOADED_LABELS = 100\n",
    "NUM_SEARCHES_TO_BE_PRELOADED = 10\n",
    "CLEAR_DB = True\n",
    "\n",
    "###########################################\n",
    "# Only change if you know what you're doing\n",
    "###########################################\n",
    "\n",
    "base = \"../\"\n",
    "settings_filepath = \"config-user-study-encode-e11-5-face-hindbrain.json\"\n",
    "window_size = 3000\n",
    "resolution = 25\n",
    "\n",
    "# Minimum value to consider a peak annotation a peak for differential accessible peak annotations\n",
    "min_peak_val_diff = 0.5 \n",
    "# Minimum value to consider a peak annotation a peak for equally accessible peak annotations\n",
    "min_peak_val_same = 1\n",
    "\n",
    "with open(os.path.join(base, settings_filepath), \"r\") as f:\n",
    "    settings = json.load(f)\n",
    "\n",
    "signal_face = \"data/ENCFF373NJX.bigWig\"\n",
    "signal_hindbrain = \"data/ENCFF943PHW.bigWig\"\n",
    "\n",
    "narrow_peaks_face = \"data/ENCFF545ITR.bigBed\"\n",
    "narrow_peaks_hindbrain = \"data/ENCFF007GMX.bigBed\"\n",
    "\n",
    "broad_peaks_face = \"data/ENCFF285BLZ.bigBed\"\n",
    "broad_peaks_hindbrain = \"data/ENCFF007GMX.bigBed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings as they just pollute the output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Enable importing modules from the parent directory\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "module_path = os.path.abspath(os.path.join('../experiments'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "module_path = os.path.abspath(os.path.join('../server'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 87129 windows from chr10 with a max value of 1.0.\n",
      "Extracted 87129 windows from chr10 with a max value of 1.0.\n"
     ]
    }
   ],
   "source": [
    "from server.bigwig import chunk\n",
    "\n",
    "windows_face = chunk(\n",
    "    signal_face,\n",
    "    window_size,\n",
    "    resolution,\n",
    "    window_size // settings['step_freq'],\n",
    "    settings['chroms'],\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "windows_hindbrain = chunk(\n",
    "    signal_hindbrain,\n",
    "    window_size,\n",
    "    resolution,\n",
    "    window_size // settings['step_freq'],\n",
    "    settings['chroms'],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get the max signal per window**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_signal_face = np.max(windows_face, axis=1)\n",
    "max_signal_hindbrain = np.max(windows_hindbrain, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find differentially accessible peaks much faster\n",
    "\n",
    "`chunk_beds_binary()` extracts only a binary value per window: `1` if a window contains an annotation, i.e., a peak, or `0` if not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 87129 windows from chr10 with a max value of 1.0.\n",
      "Extracted 87129 windows from chr10 with a max value of 1.0.\n",
      "Face peaks: 11769\n",
      "Hindbrain peaks: 11257\n",
      "Diff peaks: 644\n",
      "Same peaks: 11191\n",
      "Diff peaks with max val >= 0.5: 77\n",
      "Same peaks with max val >= 1: 1572\n"
     ]
    }
   ],
   "source": [
    "from ae.utils import chunk_beds_binary\n",
    "\n",
    "face_wins_has_peaks = chunk_beds_binary(\n",
    "    broad_peaks_face,\n",
    "    window_size,\n",
    "    window_size // settings['step_freq'],\n",
    "    settings['chroms'],\n",
    "    verbose=True,\n",
    ").flatten()\n",
    "\n",
    "hindbrain_wins_has_peaks = chunk_beds_binary(\n",
    "    broad_peaks_hindbrain,\n",
    "    window_size,\n",
    "    window_size // settings['step_freq'],\n",
    "    settings['chroms'],\n",
    "    verbose=True,\n",
    ").flatten()\n",
    "\n",
    "print('Face peaks: {}'.format(np.sum(face_wins_has_peaks)))\n",
    "print('Hindbrain peaks: {}'.format(np.sum(hindbrain_wins_has_peaks)))\n",
    "\n",
    "wins_has_diff_peak = (face_wins_has_peaks + hindbrain_wins_has_peaks) == 1\n",
    "print('Diff peaks: {}'.format(np.sum(wins_has_diff_peak)))\n",
    "\n",
    "wins_has_same_peaks = (face_wins_has_peaks + hindbrain_wins_has_peaks) == 2\n",
    "print('Same peaks: {}'.format(np.sum(wins_has_same_peaks)))\n",
    "\n",
    "diff_peaks_win_ids = np.where(wins_has_diff_peak)[0]\n",
    "same_peaks_win_ids = np.where(wins_has_same_peaks)[0]\n",
    "\n",
    "diff_peaks_with_max = wins_has_diff_peak & ((max_signal_face >= min_peak_val_diff) | (max_signal_hindbrain >= min_peak_val_diff))\n",
    "diff_peaks_with_max_ids = np.where(diff_peaks_with_max)[0]\n",
    "\n",
    "print('Diff peaks with max val >= {}: {}'.format(min_peak_val_diff, np.sum(diff_peaks_with_max)))\n",
    "\n",
    "same_peaks_with_max = wins_has_same_peaks & ((max_signal_face >= min_peak_val_same) | (max_signal_hindbrain >= min_peak_val_same))\n",
    "same_peaks_with_max_ids = np.where(same_peaks_with_max)[0]\n",
    "\n",
    "print('Same peaks with max val >= {}: {}'.format(min_peak_val_same, np.sum(same_peaks_with_max)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preload Search DB with some Labels\n",
    "\n",
    "Preload at most `MAX_PRELOADED_LABELS` positive and negative differentially accessible peaks. We are limiting the number to not overrepresent negative examples as there seem to be many more peaks that are equally accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from server.config import Config\n",
    "from server.database import DB\n",
    "\n",
    "db_path = os.path.join(base, settings[\"db_path\"])\n",
    "\n",
    "if CLEAR_DB:\n",
    "    os.remove(db_path)\n",
    "    DB(db_path=db_path, clear=True)\n",
    "else:\n",
    "    try:\n",
    "        with sqlite3.connect(db_path) as db:\n",
    "            c = db.cursor()\n",
    "            c.execute(f\"SELECT * FROM classification\")\n",
    "            c.fetchone()\n",
    "    except sqlite3.OperationalError:\n",
    "        DB(db_path=db_path, clear=CLEAR_DB)\n",
    "\n",
    "with sqlite3.connect(db_path) as db:\n",
    "    for search_id in range(NUM_SEARCHES_TO_BE_PRELOADED): \n",
    "        db.execute(f\"DELETE FROM classification WHERE search_id = {int(search_id)};\")\n",
    "        db.commit()\n",
    "\n",
    "        for window_idx in np.random.choice(\n",
    "            diff_peaks_with_max_ids,\n",
    "            np.min((diff_peaks_with_max_ids.size, MAX_PRELOADED_LABELS)),\n",
    "            replace=False\n",
    "        ):\n",
    "            db.execute(\n",
    "                \"\"\"\n",
    "                    INSERT INTO\n",
    "                        classification(search_id, window_id, is_positive)\n",
    "                    VALUES\n",
    "                        (?, ?, ?);\n",
    "                \"\"\",\n",
    "                (int(search_id), int(window_idx), 1),\n",
    "            )\n",
    "\n",
    "\n",
    "        for window_idx in np.random.choice(\n",
    "            same_peaks_with_max_ids,\n",
    "            np.min((same_peaks_with_max_ids.size, MAX_PRELOADED_LABELS)),\n",
    "            replace=False\n",
    "        ):\n",
    "            db.execute(\n",
    "                \"\"\"\n",
    "                    INSERT INTO\n",
    "                        classification(search_id, window_id, is_positive)\n",
    "                    VALUES\n",
    "                        (?, ?, ?);\n",
    "                \"\"\",\n",
    "                (int(search_id), int(window_idx), -1),\n",
    "            )\n",
    "\n",
    "        db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
